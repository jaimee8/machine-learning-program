{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+5\">#07. Why Neural Networks Deeply Learn a Mathematical Formula?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Book + Private Lessons [Here ‚Üó](https://sotastica.com/reservar)\n",
    "- Subscribe to my [Blog ‚Üó](https://blog.pythonassembly.com/)\n",
    "- Let's keep in touch on [LinkedIn ‚Üó](www.linkedin.com/in/jsulopz) üòÑ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Machine Learning, what does it mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - The Machine Learns...\n",
    ">\n",
    "> But, **what does it learn?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Machine Learning, what does it mean? ‚èØ<br><br>¬∑ The machine learns...<br><br>Ha ha, not funny! ü§® What does it learn?<br><br>¬∑ A mathematical equation. For example: <a href=\"https://t.co/sjtq9F2pq7\">pic.twitter.com/sjtq9F2pq7</a></p>&mdash; Jes√∫s L√≥pez (@sotastica) <a href=\"https://twitter.com/sotastica/status/1449735653328031745?ref_src=twsrc%5Etfw\">October 17, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Machine Learning, what does it mean? ‚èØ<br><br>¬∑ The machine learns...<br><br>Ha ha, not funny! ü§® What does it learn?<br><br>¬∑ A mathematical equation. For example: <a href=\"https://t.co/sjtq9F2pq7\">pic.twitter.com/sjtq9F2pq7</a></p>&mdash; Jes√∫s L√≥pez (@sotastica) <a href=\"https://twitter.com/sotastica/status/1449735653328031745?ref_src=twsrc%5Etfw\">October 17, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does the Machine Learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In a Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Ht3rYS-JilE\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Ht3rYS-JilE\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=329\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=329\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Practical Example ‚Üí [Tesla Autopilot](https://www.tesla.com/AI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Example where It Fails ‚Üí [Tesla Confuses Moon with Semaphore](https://twitter.com/Carnage4Life/status/1418920100086784000?s=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Simply execute the following lines of code to load the data.\n",
    "> - This dataset contains **statistics about Car Accidents** (columns)\n",
    "> - In each one of **USA States** (rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/fivethirtyeight/fivethirtyeight-bad-drivers-dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MO</th>\n",
       "      <td>16.1</td>\n",
       "      <td>6.923</td>\n",
       "      <td>5.474</td>\n",
       "      <td>14.812</td>\n",
       "      <td>13.524</td>\n",
       "      <td>790.32</td>\n",
       "      <td>144.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CT</th>\n",
       "      <td>10.8</td>\n",
       "      <td>4.968</td>\n",
       "      <td>3.888</td>\n",
       "      <td>9.396</td>\n",
       "      <td>8.856</td>\n",
       "      <td>1068.73</td>\n",
       "      <td>167.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MI</th>\n",
       "      <td>14.1</td>\n",
       "      <td>3.384</td>\n",
       "      <td>3.948</td>\n",
       "      <td>13.395</td>\n",
       "      <td>10.857</td>\n",
       "      <td>1110.61</td>\n",
       "      <td>152.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UT</th>\n",
       "      <td>11.3</td>\n",
       "      <td>4.859</td>\n",
       "      <td>1.808</td>\n",
       "      <td>9.944</td>\n",
       "      <td>10.848</td>\n",
       "      <td>809.38</td>\n",
       "      <td>109.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KY</th>\n",
       "      <td>21.4</td>\n",
       "      <td>4.066</td>\n",
       "      <td>4.922</td>\n",
       "      <td>16.692</td>\n",
       "      <td>16.264</td>\n",
       "      <td>872.51</td>\n",
       "      <td>137.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                       \n",
       "MO       16.1     6.923    5.474          14.812       13.524       790.32   \n",
       "CT       10.8     4.968    3.888           9.396        8.856      1068.73   \n",
       "MI       14.1     3.384    3.948          13.395       10.857      1110.61   \n",
       "UT       11.3     4.859    1.808           9.944       10.848       809.38   \n",
       "KY       21.4     4.066    4.922          16.692       16.264       872.51   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "MO          144.45  \n",
       "CT          167.02  \n",
       "MI          152.26  \n",
       "UT          109.48  \n",
       "KY          137.13  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset(name='car_crashes', index_col='abbrev')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Concepts in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_intercept': True,\n",
       " 'normalize': 'deprecated',\n",
       " 'copy_X': True,\n",
       " 'n_jobs': None,\n",
       " 'positive': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_intercept': True,\n",
       " 'normalize': 'deprecated',\n",
       " 'copy_X': True,\n",
       " 'n_jobs': None,\n",
       " 'positive': False,\n",
       " 'feature_names_in_': array(['speeding', 'alcohol', 'not_distracted', 'no_previous',\n",
       "        'ins_premium', 'ins_losses'], dtype=object),\n",
       " 'n_features_in_': 6,\n",
       " 'coef_': array([-0.02650334,  0.49252176,  0.17453205,  0.71257329, -0.00125105,\n",
       "         0.00643096]),\n",
       " '_residues': 35.75599620119316,\n",
       " 'rank_': 6,\n",
       " 'singular_': array([1265.56295658,  136.88075844,   40.51113699,   14.55337989,\n",
       "          10.99084201,    6.16130337]),\n",
       " 'intercept_': 1.4120634209126202}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_48148/3324602025.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fit' is not defined"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'algo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_48148/22777151.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'algo' is not defined"
     ]
    }
   ],
   "source": [
    "algo.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`algo = ?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_48148/861900531.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "algo = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:27:10.338121: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-11-17 19:27:10.338206: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "algo = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>7.332</td>\n",
       "      <td>5.640</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.040</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>7.421</td>\n",
       "      <td>4.525</td>\n",
       "      <td>16.290</td>\n",
       "      <td>17.014</td>\n",
       "      <td>1053.48</td>\n",
       "      <td>133.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>6.510</td>\n",
       "      <td>5.208</td>\n",
       "      <td>15.624</td>\n",
       "      <td>17.856</td>\n",
       "      <td>899.47</td>\n",
       "      <td>110.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>4.032</td>\n",
       "      <td>5.824</td>\n",
       "      <td>21.056</td>\n",
       "      <td>21.280</td>\n",
       "      <td>827.34</td>\n",
       "      <td>142.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>4.200</td>\n",
       "      <td>3.360</td>\n",
       "      <td>10.920</td>\n",
       "      <td>10.680</td>\n",
       "      <td>878.41</td>\n",
       "      <td>165.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                       \n",
       "AL       18.8     7.332    5.640          18.048       15.040       784.55   \n",
       "AK       18.1     7.421    4.525          16.290       17.014      1053.48   \n",
       "AZ       18.6     6.510    5.208          15.624       17.856       899.47   \n",
       "AR       22.4     4.032    5.824          21.056       21.280       827.34   \n",
       "CA       12.0     4.200    3.360          10.920       10.680       878.41   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  \n",
       "AK          133.93  \n",
       "AZ          110.35  \n",
       "AR          142.39  \n",
       "CA          165.63  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Capa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_48148/3913913123.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCapa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCapa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Capa' is not defined"
     ]
    }
   ],
   "source": [
    "algo.add(layer=Capa(6))\n",
    "algo.add(layer=Capa(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the `Weights`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to `kernel_initializer` the weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "accidents = speeding \\cdot w_1 + alcohol \\cdot w_2 \\ + ... + \\ ins\\_losses \\cdot w_7\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='zeros'))\n",
    "model.add(layer=Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a Prediction with the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Can we make a prediction for for `Washington DC` accidents\n",
    "> - With the already initialized Mathematical Equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')\n",
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                \n",
       "AL         7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 18:44:21.544653: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-17 18:44:21.548214: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-11-17 18:44:21.594698: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(AL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[ 0.90974176],\n",
       "        [-0.0821209 ],\n",
       "        [ 0.70014215]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8         0.0\n",
       "AK       18.1         0.0\n",
       "AZ       18.6         0.0\n",
       "AR       22.4         0.0\n",
       "CA       12.0         0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265.9880392156863"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fit()` the `model` and compare again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 18:45:05.965242: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 213.8209 - mse: 213.8209\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 61.9320 - mse: 61.9320\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 34.2642 - mse: 34.2642\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.6045 - mse: 28.6045\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 27.6109 - mse: 27.6109\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 27.5657 - mse: 27.5657\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.9923 - mse: 26.9923\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 27.1784 - mse: 27.1784\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.6238 - mse: 26.6238\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.6339 - mse: 26.6339\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 26.6682 - mse: 26.6682\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.0386 - mse: 26.0386\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.4421 - mse: 25.4421\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.2147 - mse: 25.2147\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.1097 - mse: 25.1097\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.5557 - mse: 25.5557\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.7952 - mse: 24.7952\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.2347 - mse: 24.2347\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.3872 - mse: 26.3872\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.1348 - mse: 23.1348\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.0382 - mse: 24.0382\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.3327 - mse: 22.3327\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.1779 - mse: 24.1779\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.2001 - mse: 23.2001\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.1331 - mse: 21.1331\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.9769 - mse: 21.9769\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.6073 - mse: 23.6073\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.2133 - mse: 20.2133\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.4452 - mse: 21.4452\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.7510 - mse: 19.7510\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.4046 - mse: 19.4046\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.9807 - mse: 19.9807\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 22.0415 - mse: 22.0415\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 19.2141 - mse: 19.2141\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.2708 - mse: 18.2708\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.7747 - mse: 17.7747\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 19.1129 - mse: 19.1129\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.9143 - mse: 16.9143\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.7033 - mse: 16.7033\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.2487 - mse: 16.2487\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.9631 - mse: 16.9631\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.5066 - mse: 16.5066\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.6251 - mse: 21.6251\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.7355 - mse: 15.7355\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.7079 - mse: 16.7079\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.8134 - mse: 14.8134\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.4142 - mse: 14.4142\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 15.6307 - mse: 15.6307\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.8343 - mse: 14.8343\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.6300 - mse: 15.6300\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.3511 - mse: 13.3511\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.2818 - mse: 19.2818\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.1813 - mse: 16.1813\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.3776 - mse: 13.3776\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9006 - mse: 12.9006\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.3162 - mse: 12.3162\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.7359 - mse: 12.7359\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.0872 - mse: 14.0872\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.6619 - mse: 11.6619\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4994 - mse: 11.4994\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.6234 - mse: 12.6234\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1898 - mse: 11.1898\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.1457 - mse: 13.1457\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.4165 - mse: 13.4165\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.9977 - mse: 12.9977\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.0685 - mse: 12.0685\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8582 - mse: 10.8582\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.8253 - mse: 9.8253\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 10.0714 - mse: 10.0714\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.5291 - mse: 10.5291\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.1776 - mse: 9.1776\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.7285 - mse: 10.7285\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4755 - mse: 11.4755\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.9083 - mse: 9.9083\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.6149 - mse: 8.6149\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.2647 - mse: 9.2647\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.1836 - mse: 8.1836\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1778 - mse: 10.1778\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5671 - mse: 9.5671\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.7448 - mse: 7.7448\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9032 - mse: 7.9032\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1866 - mse: 10.1866\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.5872 - mse: 8.5872\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.9377 - mse: 7.9377\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4268 - mse: 8.4268\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2127 - mse: 7.2127\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.6170 - mse: 6.6170\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.4456 - mse: 6.4456\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.9613 - mse: 10.9613\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7819 - mse: 8.7819\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 6.7252 - mse: 6.7252\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.0358 - mse: 6.0358\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.3392 - mse: 6.3392\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 5.8511 - mse: 5.8511\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.7777 - mse: 5.7777\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.3654 - mse: 6.3654\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2532 - mse: 9.2532\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.1042 - mse: 8.1042\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1539 - mse: 7.1539\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.1430 - mse: 7.1430\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.6979 - mse: 5.6979\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.0222 - mse: 5.0222\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.2242 - mse: 5.2242\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.6462 - mse: 5.6462\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.3536 - mse: 7.3536\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.9346 - mse: 4.9346\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.8621 - mse: 4.8621\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.6096 - mse: 5.6096\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 6.0538 - mse: 6.0538\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.9376 - mse: 4.9376\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 6.1155 - mse: 6.1155\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.2115 - mse: 6.2115\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.1543 - mse: 4.1543\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.0766 - mse: 5.0766\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.2259 - mse: 7.2259\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 4.6681 - mse: 4.6681\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.1601 - mse: 5.1601\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 6.1131 - mse: 6.1131\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.6168 - mse: 4.6168\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.9167 - mse: 3.9167\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.9055 - mse: 3.9055\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.3448 - mse: 5.3448\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.1572 - mse: 5.1572\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.4769 - mse: 3.4769\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.3125 - mse: 4.3125\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.3521 - mse: 6.3521\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.4231 - mse: 4.4231\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 3.3598 - mse: 3.3598\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.7371 - mse: 3.7371\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.4886 - mse: 4.4886\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.3457 - mse: 4.3457\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.3594 - mse: 4.3594\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.0276 - mse: 3.0276\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.9846 - mse: 2.9846\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.9191 - mse: 2.9191\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8622 - mse: 2.8622\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.5708 - mse: 4.5708\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1145 - mse: 9.1145\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.8126 - mse: 3.8126\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7554 - mse: 2.7554\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8668 - mse: 2.8668\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.8954 - mse: 2.8954\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.9493 - mse: 2.9493\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.8909 - mse: 3.8909\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 5.3989 - mse: 5.3989\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.0712 - mse: 5.0712\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.5542 - mse: 2.5542\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3218 - mse: 3.3218\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.5612 - mse: 3.5612\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.6973 - mse: 4.6973\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.2913 - mse: 3.2913\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 2.4241 - mse: 2.4241\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.7295 - mse: 2.7295\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.4596 - mse: 3.4596\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.1079 - mse: 6.1079\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.4379 - mse: 6.4379\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.4221 - mse: 2.4221\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.2363 - mse: 3.2363\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3260 - mse: 2.3260\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 2.6898 - mse: 2.6898\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.9906 - mse: 3.9906\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 4.0427 - mse: 4.0427\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.9380 - mse: 2.9380\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.7955 - mse: 4.7955\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1715 - mse: 4.1715\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.9958 - mse: 2.9958\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.4229 - mse: 3.4229\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7102 - mse: 2.7102\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1363 - mse: 2.1363\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1853 - mse: 2.1853\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8545 - mse: 2.8545\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.0129 - mse: 2.0129\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.1715 - mse: 6.1715\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.5916 - mse: 5.5916\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0708 - mse: 2.0708\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8533 - mse: 2.8533\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2775 - mse: 3.2775\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0945 - mse: 3.0945\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.1094 - mse: 6.1094\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.3840 - mse: 4.3840\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3606 - mse: 2.3606\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9779 - mse: 1.9779\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.2305 - mse: 2.2305\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7695 - mse: 2.7695\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.9776 - mse: 3.9776\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.9187 - mse: 4.9187\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.5276 - mse: 3.5276\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3781 - mse: 2.3781\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.0470 - mse: 3.0470\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3890 - mse: 2.3890\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8999 - mse: 1.8999\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.8841 - mse: 1.8841\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.6904 - mse: 3.6904\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.7296 - mse: 5.7296\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2837 - mse: 3.2837\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9034 - mse: 1.9034\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2040 - mse: 2.2040\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8989 - mse: 1.8989\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.3554 - mse: 4.3554\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.0662 - mse: 6.0662\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.6914 - mse: 2.6914\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8131 - mse: 1.8131\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8099 - mse: 1.8099\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.7889 - mse: 2.7889\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.3410 - mse: 4.3410\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.8989 - mse: 2.8989\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.9183 - mse: 2.9183\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 2.4048 - mse: 2.4048\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.3368 - mse: 2.3368\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.6788 - mse: 2.6788\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.8876 - mse: 3.8876\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.4930 - mse: 2.4930\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.7689 - mse: 1.7689\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9330 - mse: 1.9330\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1158 - mse: 2.1158\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 5.7123 - mse: 5.7123\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.8072 - mse: 3.8072\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7208 - mse: 1.7208\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.8008 - mse: 1.8008\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7754 - mse: 1.7754\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6606 - mse: 1.6606\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.1132 - mse: 3.1132\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.4549 - mse: 4.4549\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.1119 - mse: 3.1119\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.4791 - mse: 2.4791\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.8865 - mse: 1.8865\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.7124 - mse: 1.7124\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3575 - mse: 2.3575\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.6876 - mse: 4.6876\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.0584 - mse: 4.0584\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.7567 - mse: 3.7567\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.6804 - mse: 3.6804\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7834 - mse: 1.7834\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8403 - mse: 1.8403\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7128 - mse: 1.7128\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.7010 - mse: 3.7010\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.1899 - mse: 3.1899\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.0128 - mse: 2.0128\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1226 - mse: 2.1226\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9538 - mse: 1.9538\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.6226 - mse: 1.6226\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.6358 - mse: 1.6358\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.2447 - mse: 2.2447\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.9940 - mse: 5.9940\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.7042 - mse: 4.7042\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.4372 - mse: 3.4372\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.1928 - mse: 2.1928\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.0563 - mse: 2.0563\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.4435 - mse: 2.4435\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.1373 - mse: 2.1373\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.6706 - mse: 2.6706\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.4210 - mse: 3.4210\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8429 - mse: 1.8429\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6225 - mse: 1.6225\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6816 - mse: 1.6816\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.4927 - mse: 3.4927\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 4.8043 - mse: 4.8043\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7609 - mse: 1.7609\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.5658 - mse: 1.5658\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6212 - mse: 1.6212\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7461 - mse: 1.7461\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.1639 - mse: 2.1639\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.5912 - mse: 1.5912\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5884 - mse: 1.5884\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.4286 - mse: 3.4286\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2981 - mse: 7.2981\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.7793 - mse: 3.7793\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.5918 - mse: 1.5918\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5623 - mse: 1.5623\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5306 - mse: 1.5306\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5994 - mse: 1.5994\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.2291 - mse: 2.2291\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2179 - mse: 3.2179\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.8556 - mse: 4.8556\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.6350 - mse: 4.6350\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8345 - mse: 1.8345\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5199 - mse: 1.5199\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6548 - mse: 1.6548\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9846 - mse: 1.9846\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.1445 - mse: 3.1445\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.7995 - mse: 2.7995\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4445 - mse: 2.4445\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6992 - mse: 1.6992\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.4937 - mse: 1.4937\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.2473 - mse: 2.2473\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.9850 - mse: 5.9850\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.7314 - mse: 3.7314\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2204 - mse: 3.2204\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8807 - mse: 1.8807\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.8511 - mse: 1.8511\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7288 - mse: 1.7288\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7874 - mse: 2.7874\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.6319 - mse: 2.6319\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7061 - mse: 1.7061\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9467 - mse: 1.9467\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.9694 - mse: 3.9694\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.5244 - mse: 4.5244\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.3633 - mse: 4.3633\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0130 - mse: 2.0130\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0690 - mse: 2.0690\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7384 - mse: 2.7384\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4560 - mse: 2.4560\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6090 - mse: 1.6090\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4568 - mse: 1.4568\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3641 - mse: 2.3641\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8966 - mse: 2.8966\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3108 - mse: 3.3108\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5319 - mse: 1.5319\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5666 - mse: 1.5666\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7197 - mse: 2.7197\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.5973 - mse: 6.5973\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.5561 - mse: 4.5561\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6452 - mse: 1.6452\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5128 - mse: 1.5128\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.2137 - mse: 2.2137\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5605 - mse: 1.5605\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0622 - mse: 2.0622\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8308 - mse: 1.8308\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.4609 - mse: 3.4609\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.8971 - mse: 4.8971\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7732 - mse: 1.7732\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4148 - mse: 1.4148\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6000 - mse: 1.6000\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4611 - mse: 1.4611\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3461 - mse: 3.3461\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.2296 - mse: 4.2296\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1783 - mse: 4.1783\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8370 - mse: 1.8370\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.4090 - mse: 1.4090\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.8434 - mse: 1.8434\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.2780 - mse: 4.2780\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.5021 - mse: 2.5021\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4422 - mse: 1.4422\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3981 - mse: 1.3981\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.2243 - mse: 2.2243\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1651 - mse: 4.1651\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.7132 - mse: 3.7132\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4459 - mse: 2.4459\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4757 - mse: 1.4757\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5187 - mse: 1.5187\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.3755 - mse: 1.3755\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9322 - mse: 1.9322\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.1270 - mse: 3.1270\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7890 - mse: 2.7890\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0053 - mse: 3.0053\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.3281 - mse: 4.3281\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4116 - mse: 1.4116\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3936 - mse: 2.3936\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.9477 - mse: 3.9477\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8637 - mse: 1.8637\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4166 - mse: 1.4166\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5195 - mse: 1.5195\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5337 - mse: 1.5337\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3769 - mse: 1.3769\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3969 - mse: 1.3969\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3531 - mse: 1.3531\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8981 - mse: 1.8981\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.6489 - mse: 6.6489\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.9886 - mse: 2.9886\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5456 - mse: 1.5456\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1879 - mse: 2.1879\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7309 - mse: 2.7309\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.6576 - mse: 2.6576\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4617 - mse: 1.4617\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4172 - mse: 1.4172\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8306 - mse: 1.8306\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.1362 - mse: 3.1362\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.8721 - mse: 4.8721\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9326 - mse: 1.9326\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7343 - mse: 1.7343\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9486 - mse: 1.9486\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3535 - mse: 1.3535\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4745 - mse: 1.4745\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9813 - mse: 1.9813\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7191 - mse: 2.7191\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.1658 - mse: 6.1658\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1816 - mse: 2.1816\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6537 - mse: 1.6537\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3237 - mse: 1.3237\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3980 - mse: 1.3980\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.1926 - mse: 2.1926\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9496 - mse: 1.9496\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.5666 - mse: 1.5666\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.3554 - mse: 3.3554\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 5.9617 - mse: 5.9617\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 2.3780 - mse: 2.3780\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.5269 - mse: 1.5269\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9342 - mse: 1.9342\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7299 - mse: 1.7299\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.3725 - mse: 1.3725\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5033 - mse: 1.5033\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4156 - mse: 1.4156\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3262 - mse: 1.3262\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.7709 - mse: 2.7709\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1774 - mse: 7.1774\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1647 - mse: 2.1647\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3647 - mse: 1.3647\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5943 - mse: 1.5943\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4223 - mse: 1.4223\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3550 - mse: 2.3550\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.2982 - mse: 5.2982\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8494 - mse: 2.8494\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.2368 - mse: 2.2368\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9090 - mse: 1.9090\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6048 - mse: 1.6048\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8883 - mse: 1.8883\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3292 - mse: 1.3292\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7077 - mse: 1.7077\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.5460 - mse: 3.5460\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.2080 - mse: 4.2080\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8826 - mse: 1.8826\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4286 - mse: 1.4286\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3374 - mse: 1.3374\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3043 - mse: 1.3043\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.8902 - mse: 1.8902\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1011 - mse: 4.1011\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.6826 - mse: 3.6826\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4117 - mse: 1.4117\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0368 - mse: 2.0368\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.6713 - mse: 2.6713\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5623 - mse: 1.5623\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0178 - mse: 2.0178\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.9674 - mse: 3.9674\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.9518 - mse: 4.9518\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7783 - mse: 1.7783\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2704 - mse: 1.2704\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2628 - mse: 1.2628\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3884 - mse: 1.3884\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3993 - mse: 1.3993\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2619 - mse: 1.2619\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2499 - mse: 1.2499\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.1539 - mse: 2.1539\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.9532 - mse: 6.9532\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9792 - mse: 1.9792\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4599 - mse: 1.4599\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2567 - mse: 1.2567\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5903 - mse: 1.5903\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7509 - mse: 2.7509\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0261 - mse: 3.0261\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2758 - mse: 3.2758\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8475 - mse: 1.8475\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5766 - mse: 1.5766\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2388 - mse: 1.2388\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2440 - mse: 1.2440\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3971 - mse: 1.3971\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9806 - mse: 1.9806\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.9593 - mse: 3.9593\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7768 - mse: 1.7768\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2285 - mse: 1.2285\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.3405 - mse: 1.3405\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6226 - mse: 1.6226\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.5353 - mse: 3.5353\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.0177 - mse: 6.0177\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.5364 - mse: 3.5364\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5411 - mse: 1.5411\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2411 - mse: 1.2411\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.3245 - mse: 1.3245\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.3920 - mse: 1.3920\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.2703 - mse: 1.2703\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.3854 - mse: 1.3854\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4939 - mse: 2.4939\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.8412 - mse: 5.8412\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.1704 - mse: 3.1704\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.8856 - mse: 1.8856\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8538 - mse: 1.8538\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6215 - mse: 1.6215\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5333 - mse: 1.5333\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6454 - mse: 1.6454\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.8529 - mse: 3.8529\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.7624 - mse: 3.7624\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.8228 - mse: 1.8228\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2516 - mse: 2.2516\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 2.5386 - mse: 2.5386\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3398 - mse: 1.3398\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7178 - mse: 1.7178\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.7789 - mse: 2.7789\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8659 - mse: 2.8659\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3004 - mse: 2.3004\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6493 - mse: 1.6493\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2227 - mse: 1.2227\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.9084 - mse: 1.9084\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.7198 - mse: 4.7198\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6154 - mse: 1.6154\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8426 - mse: 1.8426\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.5297 - mse: 2.5297\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1369 - mse: 2.1369\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.1929 - mse: 3.1929\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.1921 - mse: 3.1921\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.5688 - mse: 1.5688\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2063 - mse: 1.2063\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3311 - mse: 1.3311\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9151 - mse: 1.9151\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3623 - mse: 3.3623\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1801 - mse: 2.1801\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.1942 - mse: 1.1942\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7327 - mse: 1.7327\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2491 - mse: 2.2491\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0629 - mse: 3.0629\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2192 - mse: 3.2192\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0273 - mse: 2.0273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1598ea700>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.10976417, -0.11118057,  0.10978648],\n",
       "        [ 0.23281783, -0.23475456,  0.23286201],\n",
       "        [ 0.16636847, -0.16802043,  0.16640036],\n",
       "        [ 0.25329313, -0.25511673,  0.2533335 ],\n",
       "        [-0.00053986,  0.00288974, -0.00065306],\n",
       "        [ 0.00953689, -0.00785372,  0.00944587]], dtype=float32),\n",
       " array([ 0.10179962, -0.10132063,  0.10175249], dtype=float32),\n",
       " array([[ 0.9725532 ],\n",
       "        [-0.14655806],\n",
       "        [ 0.7630058 ]], dtype=float32),\n",
       " array([0.10198415], dtype=float32)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 18:48:45.338026: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>18.536709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>17.871172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>17.982235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>21.744883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>12.802050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8   18.536709\n",
       "AK       18.1   17.871172\n",
       "AZ       18.6   17.982235\n",
       "AR       22.4   21.744883\n",
       "CA       12.0   12.802050"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2447601343428383"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to `kernel_initializer` the weights to 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='ones'))\n",
    "model.add(layer=Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a Prediction with the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Can we make a prediction for for `Washington DC` accidents\n",
    "> - With the already initialized Mathematical Equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')\n",
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                \n",
       "AL         7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 18:49:23.308396: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[138.81078]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(AL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[ 0.04539084],\n",
       "        [-0.9930145 ],\n",
       "        [ 1.089893  ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>138.810776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>175.369736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>150.096710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>145.388153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>152.683411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8  138.810776\n",
       "AK       18.1  175.369736\n",
       "AZ       18.6  150.096710\n",
       "AR       22.4  145.388153\n",
       "CA       12.0  152.683411"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18975.672927183088"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fit()` the `model` and compare again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17194.9180 - mse: 17194.9180\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10998.2285 - mse: 10998.2285\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7899.6123 - mse: 7899.6123\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5772.9756 - mse: 5772.9756\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4201.3472 - mse: 4201.3472\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3044.2864 - mse: 3044.2864\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2186.9197 - mse: 2186.9197\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1534.6572 - mse: 1534.6572\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1059.9769 - mse: 1059.9769\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 716.4389 - mse: 716.4389\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 468.6841 - mse: 468.6841\n",
      "Epoch 12/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 297.4897 - mse: 297.4897"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 18:49:55.028314: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 295.3433 - mse: 295.3433\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 181.1785 - mse: 181.1785\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 111.0138 - mse: 111.0138\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 71.1494 - mse: 71.1494\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 48.0297 - mse: 48.0297\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 35.8477 - mse: 35.8477\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.4103 - mse: 30.4103\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.4600 - mse: 28.4600\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 28.2400 - mse: 28.2400\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.5942 - mse: 27.5942\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.2985 - mse: 27.2985\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.2281 - mse: 27.2281\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.1524 - mse: 27.1524\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 27.1940 - mse: 27.1940\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.3928 - mse: 27.3928\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.4688 - mse: 27.4688\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.6941 - mse: 27.6941\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 27.0951 - mse: 27.0951\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.2445 - mse: 27.2445\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.9607 - mse: 26.9607\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 26.0742 - mse: 26.0742\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.7284 - mse: 26.7284\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.9313 - mse: 26.9313\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 25.5554 - mse: 25.5554\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 33.3589 - mse: 33.3589\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 34.4680 - mse: 34.4680\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.8564 - mse: 26.8564\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.6611 - mse: 27.6611\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.9559 - mse: 28.9559\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.9224 - mse: 23.9224\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.9148 - mse: 26.9148\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.7388 - mse: 28.7388\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 32.5894 - mse: 32.5894\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 38.8184 - mse: 38.8184\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.9624 - mse: 26.9624\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.2112 - mse: 22.2112\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 33.1017 - mse: 33.1017\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 37.1945 - mse: 37.1945\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.9206 - mse: 24.9206\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.1125 - mse: 27.1125\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 32.0426 - mse: 32.0426\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 52.5856 - mse: 52.5856\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 34.5700 - mse: 34.5700\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.4816 - mse: 24.4816\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 19.9070 - mse: 19.9070\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.2089 - mse: 21.2089\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.8108 - mse: 25.8108\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.2974 - mse: 19.2974\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.5026 - mse: 26.5026\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 34.3856 - mse: 34.3856\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.9885 - mse: 25.9885\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 35.0245 - mse: 35.0245\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 29.8692 - mse: 29.8692\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.9644 - mse: 18.9644\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.1756 - mse: 18.1756\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.2272 - mse: 22.2272\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 30.6969 - mse: 30.6969\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 26.8575 - mse: 26.8575\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 19.7964 - mse: 19.7964\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.7940 - mse: 16.7940\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 49.9807 - mse: 49.9807\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 27.9693 - mse: 27.9693\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.0226 - mse: 16.0226\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.2441 - mse: 16.2441\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.4239 - mse: 16.4239\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 20.5491 - mse: 20.5491\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.1211 - mse: 15.1211\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 31.0367 - mse: 31.0367\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.6594 - mse: 23.6594\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 26.0680 - mse: 26.0680\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.7918 - mse: 16.7918\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.7023 - mse: 23.7023\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 40.9617 - mse: 40.9617\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.6277 - mse: 29.6277\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 23.4581 - mse: 23.4581\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 15.3556 - mse: 15.3556\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 14.3253 - mse: 14.3253\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.3469 - mse: 14.3469\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.4661 - mse: 25.4661\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 20.5596 - mse: 20.5596\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.7411 - mse: 18.7411\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 20.8717 - mse: 20.8717\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 33.8568 - mse: 33.8568\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 14.7624 - mse: 14.7624\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 14.8314 - mse: 14.8314\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.4270 - mse: 13.4270\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.1827 - mse: 25.1827\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 33.7483 - mse: 33.7483\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.7514 - mse: 18.7514\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 17.1515 - mse: 17.1515\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.8003 - mse: 11.8003\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.7064 - mse: 12.7064\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.5480 - mse: 23.5480\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 27.5522 - mse: 27.5522\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 19.5598 - mse: 19.5598\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 31.6913 - mse: 31.6913\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.0353 - mse: 24.0353\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.4284 - mse: 18.4284\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.1462 - mse: 13.1462\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.1683 - mse: 12.1683\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.8115 - mse: 12.8115\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.4644 - mse: 10.4644\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.6847 - mse: 11.6847\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 48.2715 - mse: 48.2715\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 28.5102 - mse: 28.5102\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.0704 - mse: 16.0704\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0541 - mse: 10.0541\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0619 - mse: 11.0619\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0590 - mse: 10.0590\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.4318 - mse: 14.4318\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.5737 - mse: 9.5737\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.8408 - mse: 14.8408\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 33.8651 - mse: 33.8651\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.7220 - mse: 11.7220\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7641 - mse: 8.7641\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.8230 - mse: 9.8230\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.6908 - mse: 11.6908\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7987 - mse: 9.7987\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.8918 - mse: 11.8918\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.8736 - mse: 21.8736\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 30.4389 - mse: 30.4389\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.1397 - mse: 26.1397\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.1157 - mse: 13.1157\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.8642 - mse: 8.8642\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7733 - mse: 8.7733\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.7987 - mse: 7.7987\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9566 - mse: 7.9566\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 9.4907 - mse: 9.4907\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 34.8820 - mse: 34.8820\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 38.5622 - mse: 38.5622\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 7.8274 - mse: 7.8274\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.3230 - mse: 7.3230\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.2971 - mse: 7.2971\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.9393 - mse: 7.9393\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2015 - mse: 11.2015\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 28.5106 - mse: 28.5106\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.9398 - mse: 21.9398\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.5983 - mse: 12.5983\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.5226 - mse: 8.5226\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.2263 - mse: 10.2263\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 15.0839 - mse: 15.0839\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 30.6584 - mse: 30.6584\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.5146 - mse: 16.5146\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.6224 - mse: 6.6224\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.3513 - mse: 6.3513\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 8.0539 - mse: 8.0539\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.8721 - mse: 21.8721\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 34.5152 - mse: 34.5152\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.6343 - mse: 14.6343\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3012 - mse: 8.3012\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.9732 - mse: 5.9732\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.8817 - mse: 5.8817\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.0528 - mse: 6.0528\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9606 - mse: 7.9606\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.2894 - mse: 21.2894\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 40.8236 - mse: 40.8236\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.3142 - mse: 7.3142\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.0937 - mse: 6.0937\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4371 - mse: 11.4371\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.3927 - mse: 7.3927\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.5665 - mse: 5.5665\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.9889 - mse: 5.9889\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 22.9815 - mse: 22.9815\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 42.3575 - mse: 42.3575\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.9174 - mse: 6.9174\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.2864 - mse: 5.2864\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.2992 - mse: 6.2992\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.6346 - mse: 6.6346\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.2129 - mse: 5.2129\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.8529 - mse: 4.8529\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.2957 - mse: 5.2957\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.4706 - mse: 5.4706\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.1134 - mse: 30.1134\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 50.1499 - mse: 50.1499\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 5.8812 - mse: 5.8812\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.3763 - mse: 5.3763\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.4558 - mse: 5.4558\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.1449 - mse: 6.1449\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 10.9729 - mse: 10.9729\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 24.3776 - mse: 24.3776\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 18.5675 - mse: 18.5675\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 12.4354 - mse: 12.4354\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 6.2026 - mse: 6.2026\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.9163 - mse: 5.9163\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 8.8838 - mse: 8.8838\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 22.0630 - mse: 22.0630\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.2517 - mse: 7.2517\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.1534 - mse: 5.1534\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.1451 - mse: 5.1451\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3594 - mse: 8.3594\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 20.0470 - mse: 20.0470\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 20.4346 - mse: 20.4346\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 8.2626 - mse: 8.2626\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.9443 - mse: 8.9443\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 12.9886 - mse: 12.9886\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 17.4846 - mse: 17.4846\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.9933 - mse: 7.9933\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.3171 - mse: 4.3171\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.8653 - mse: 6.8653\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.6979 - mse: 19.6979\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.7407 - mse: 18.7407\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.3981 - mse: 14.3981\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.6555 - mse: 3.6555\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.8630 - mse: 8.8630\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.9710 - mse: 19.9710\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.2371 - mse: 19.2371\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.8812 - mse: 5.8812\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.5245 - mse: 3.5245\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.9004 - mse: 3.9004\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.6708 - mse: 13.6708\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 32.6869 - mse: 32.6869\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.6791 - mse: 11.6791\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.5965 - mse: 4.5965\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.4216 - mse: 4.4216\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 4.8980 - mse: 4.8980\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.3437 - mse: 4.3437\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.3142 - mse: 4.3142\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.7055 - mse: 15.7055\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 31.9601 - mse: 31.9601\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.7711 - mse: 11.7711\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.9227 - mse: 4.9227\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.0951 - mse: 7.0951\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.0920 - mse: 12.0920\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.8721 - mse: 8.8721\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4567 - mse: 8.4567\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.3281 - mse: 5.3281\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 4.4482 - mse: 4.4482\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5259 - mse: 8.5259\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.2018 - mse: 23.2018\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.5547 - mse: 18.5547\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2160 - mse: 10.2160\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.3046 - mse: 7.3046\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9312 - mse: 10.9312\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 12.3039 - mse: 12.3039\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 14.4833 - mse: 14.4833\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.4694 - mse: 11.4694\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.9631 - mse: 3.9631\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.9949 - mse: 5.9949\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.8600 - mse: 13.8600\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.7757 - mse: 7.7757\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.8918 - mse: 3.8918\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.3246 - mse: 8.3246\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 31.0614 - mse: 31.0614\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.9692 - mse: 15.9692\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.5677 - mse: 5.5677\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.7818 - mse: 2.7818\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.4710 - mse: 3.4710\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.0132 - mse: 5.0132\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.2153 - mse: 8.2153\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.4339 - mse: 13.4339\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.1015 - mse: 25.1015\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.7335 - mse: 17.7335\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.3866 - mse: 10.3866\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.4360 - mse: 8.4360\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.8414 - mse: 4.8414\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 6.9845 - mse: 6.9845\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.2131 - mse: 11.2131\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 15.3374 - mse: 15.3374\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 9.7869 - mse: 9.7869\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.3451 - mse: 10.3451\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.1495 - mse: 11.1495\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.1113 - mse: 11.1113\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.7358 - mse: 5.7358\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.6560 - mse: 3.6560\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.7304 - mse: 5.7304\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.3651 - mse: 7.3651\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.6635 - mse: 14.6635\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.4243 - mse: 21.4243\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.0174 - mse: 12.0174\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7169 - mse: 8.7169\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5210 - mse: 8.5210\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0333 - mse: 10.0333\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7405 - mse: 9.7405\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.0571 - mse: 9.0571\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4359 - mse: 11.4359\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.2969 - mse: 13.2969\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.5689 - mse: 9.5689\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.0646 - mse: 9.0646\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.9999 - mse: 13.9999\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.5386 - mse: 12.5386\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1935 - mse: 10.1935\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.3341 - mse: 6.3341\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0080 - mse: 3.0080\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8388 - mse: 2.8388\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.3734 - mse: 4.3734\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.9290 - mse: 20.9290\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 28.5069 - mse: 28.5069\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.1437 - mse: 12.1437\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.5126 - mse: 3.5126\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 2.9993 - mse: 2.9993\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.6100 - mse: 4.6100\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.3735 - mse: 11.3735\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.1049 - mse: 18.1049\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.2399 - mse: 13.2399\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 6.7319 - mse: 6.7319\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.0117 - mse: 8.0117\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 8.7539 - mse: 8.7539\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 13.3931 - mse: 13.3931\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.0082 - mse: 12.0082\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.8392 - mse: 7.8392\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 4.7468 - mse: 4.7468\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.5823 - mse: 2.5823\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.1523 - mse: 2.1523\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.3750 - mse: 2.3750\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.0846 - mse: 13.0846\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 40.0240 - mse: 40.0240\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 18.3214 - mse: 18.3214\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.1430 - mse: 6.1430\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.4879 - mse: 2.4879\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.9058 - mse: 3.9058\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.4475 - mse: 3.4475\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.4190 - mse: 2.4190\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.1781 - mse: 3.1781\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 14.5392 - mse: 14.5392\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.2653 - mse: 22.2653\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.7871 - mse: 18.7871\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.8322 - mse: 11.8322\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 6.5983 - mse: 6.5983\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.4860 - mse: 2.4860\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.2334 - mse: 3.2334\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.9367 - mse: 7.9367\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.2401 - mse: 14.2401\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.3264 - mse: 14.3264\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.5639 - mse: 11.5639\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.8461 - mse: 9.8461\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2601 - mse: 7.2601\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.3232 - mse: 10.3232\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.1913 - mse: 7.1913\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.6140 - mse: 8.6140\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 4.4957 - mse: 4.4957\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.6750 - mse: 5.6750\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 19.7671 - mse: 19.7671\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 14.6162 - mse: 14.6162\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 4.3552 - mse: 4.3552\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.1306 - mse: 7.1306\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 13.7326 - mse: 13.7326\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 7.1945 - mse: 7.1945\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.0693 - mse: 4.0693\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1929 - mse: 4.1929\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2011 - mse: 7.2011\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 10.0270 - mse: 10.0270\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.8038 - mse: 16.8038\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.3054 - mse: 14.3054\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.6716 - mse: 12.6716\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.0871 - mse: 6.0871\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 5.1853 - mse: 5.185 - 0s 7ms/step - loss: 4.7353 - mse: 4.7353\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.9622 - mse: 3.9622\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2385 - mse: 2.2385\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.1338 - mse: 2.1338\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.8099 - mse: 5.8099\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.4657 - mse: 25.4657\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.5028 - mse: 23.5028\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1954 - mse: 4.1954\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.8251 - mse: 2.8251\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.4360 - mse: 2.4360\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.2948 - mse: 4.2948\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.0864 - mse: 6.0864\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.4729 - mse: 13.4729\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.8570 - mse: 20.8570\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.2332 - mse: 14.2332\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.8000 - mse: 6.8000\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.8527 - mse: 3.8527\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1628 - mse: 2.1628\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.0296 - mse: 4.0296\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4241 - mse: 11.4241\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.6577 - mse: 18.6577\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.4239 - mse: 11.4239\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.8585 - mse: 5.8585\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.4702 - mse: 6.4702\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6698 - mse: 8.6698\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.4808 - mse: 5.4808\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 5.9007 - mse: 5.9007\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.5317 - mse: 9.5317\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.3709 - mse: 18.3709\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.9078 - mse: 15.9078\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.0130 - mse: 9.0130\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.1956 - mse: 8.1956\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 6.1627 - mse: 6.1627\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.1710 - mse: 10.1710\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.2967 - mse: 13.2967\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.3513 - mse: 8.3513\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 5.8041 - mse: 5.8041\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 5.2513 - mse: 5.2513\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.9776 - mse: 5.9776\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.0522 - mse: 9.0522\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.6641 - mse: 16.6641\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.8904 - mse: 12.8904\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.1917 - mse: 4.1917\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8301 - mse: 2.8301\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.2170 - mse: 3.2170\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.9815 - mse: 3.9815\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 9.0565 - mse: 9.0565\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.1853 - mse: 24.1853\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.5560 - mse: 19.5560\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9222 - mse: 7.9222\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.3782 - mse: 5.3782\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0165 - mse: 7.0165\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.7093 - mse: 7.7093\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7099 - mse: 9.7099\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9086 - mse: 10.9086\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4356 - mse: 8.4356\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.5270 - mse: 4.5270\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.2638 - mse: 7.2638\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.4933 - mse: 16.4933\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1488 - mse: 11.1488\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.3909 - mse: 5.3909\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.2810 - mse: 4.2810\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.8740 - mse: 5.8740\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3951 - mse: 11.3951\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.0904 - mse: 21.0904\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.7209 - mse: 11.7209\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.6396 - mse: 3.6396\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.2637 - mse: 3.2637\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.7313 - mse: 3.7313\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.6393 - mse: 8.6393\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.2441 - mse: 15.2441\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.5202 - mse: 11.5202\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.9055 - mse: 4.9055\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.1969 - mse: 4.1969\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.8647 - mse: 7.8647\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.3221 - mse: 6.3221\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.0645 - mse: 4.0645\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 6.4217 - mse: 6.4217\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 11.9312 - mse: 11.9312\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.1483 - mse: 10.1483\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 13.6175 - mse: 13.6175\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.1234 - mse: 13.1234\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 13.7818 - mse: 13.7818\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.4022 - mse: 8.4022\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.3199 - mse: 3.3199\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 2.8725 - mse: 2.8725\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0197 - mse: 2.0197\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.8786 - mse: 1.8786\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.1097 - mse: 2.1097\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.1006 - mse: 7.1006\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 41.1612 - mse: 41.1612\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 12.7972 - mse: 12.7972\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 6.1857 - mse: 6.1857\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 3.0179 - mse: 3.0179\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.0188 - mse: 4.0188\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 6.5005 - mse: 6.5005\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 11.5306 - mse: 11.5306\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.9797 - mse: 13.9797\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.5709 - mse: 11.5709\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6754 - mse: 7.6754\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.7529 - mse: 6.7529\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.2003 - mse: 4.2003\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.2195 - mse: 4.2195\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.3459 - mse: 5.3459\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.7037 - mse: 9.7037\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.8323 - mse: 16.8323\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.5444 - mse: 12.5444\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.9459 - mse: 5.9459\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.9491 - mse: 3.9491\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.1272 - mse: 3.1272\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.9469 - mse: 4.9469\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.0121 - mse: 15.0121\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.9429 - mse: 23.9429\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.1316 - mse: 11.1316\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.5108 - mse: 3.5108\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.0030 - mse: 2.0030\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3083 - mse: 2.3083\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.5636 - mse: 3.5636\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.1933 - mse: 11.1933\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.5517 - mse: 26.5517\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6306 - mse: 10.6306\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.5011 - mse: 3.5011\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.6546 - mse: 3.6546\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.8809 - mse: 6.8809\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.9540 - mse: 9.9540\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.9097 - mse: 11.9097\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.3162 - mse: 11.3162\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.9022 - mse: 11.9022\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6651 - mse: 7.6651\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8024 - mse: 2.8024\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0968 - mse: 2.0968\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6808 - mse: 1.6808\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7498 - mse: 1.7498\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2801 - mse: 11.2801\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 35.8352 - mse: 35.8352\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5950 - mse: 8.5950\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4557 - mse: 2.4557\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6743 - mse: 1.6743\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1515 - mse: 2.1515\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.4902 - mse: 4.4902\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7796 - mse: 8.7796\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.2835 - mse: 22.2835\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.4586 - mse: 14.4586\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.0711 - mse: 6.0711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15bdcdfd0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.0803863 , 0.900651  , 1.0986634 ],\n",
       "        [1.1429759 , 0.83845484, 1.1608735 ],\n",
       "        [1.112536  , 0.8686107 , 1.1307063 ],\n",
       "        [1.1362538 , 0.8452662 , 1.1540655 ],\n",
       "        [0.95242155, 1.0328588 , 0.96668226],\n",
       "        [0.96591276, 1.0182456 , 0.9812393 ]], dtype=float32),\n",
       " array([ 0.02067563, -0.03774948,  0.03717197], dtype=float32),\n",
       " array([[ 0.0204669],\n",
       "        [-1.0184165],\n",
       "        [ 1.0650133]], dtype=float32),\n",
       " array([0.03745592], dtype=float32)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 18:50:31.531885: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>18.280220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>16.944523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>16.857445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>20.723339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>12.649424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8   18.280220\n",
       "AK       18.1   16.944523\n",
       "AZ       18.6   16.857445\n",
       "AR       22.4   20.723339\n",
       "CA       12.0   12.649424"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4798831092193554"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to `kernel_initializer` the weights to `glorot_uniform` (default)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a Prediction with the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Can we make a prediction for for `Washington DC` accidents\n",
    "> - With the already initialized Mathematical Equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')\n",
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                \n",
       "AL         7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x15c8f5670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 18:53:43.200876: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[99.78448]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(AL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.6064944 , -0.05474722,  0.46676135],\n",
       "        [ 0.03026056, -0.66200966,  0.7265953 ],\n",
       "        [ 0.3309511 ,  0.48746276, -0.1870107 ],\n",
       "        [-0.6015929 ,  0.79233575, -0.248079  ],\n",
       "        [-0.14898151,  0.59505224,  0.632252  ],\n",
       "        [-0.40874237, -0.42809725, -0.4343371 ]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[ 0.4964267 ],\n",
       "        [ 0.73119414],\n",
       "        [-0.28051603]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>99.784477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>154.049133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>134.372482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>112.065483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>104.449394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8   99.784477\n",
       "AK       18.1  154.049133\n",
       "AZ       18.6  134.372482\n",
       "AR       22.4  112.065483\n",
       "CA       12.0  104.449394"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11651.052261500548"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fit()` the `model` and compare again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11019.3604 - mse: 11019.3604\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8397.8555 - mse: 8397.8555\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6842.3765 - mse: 6842.3765\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5687.1836 - mse: 5687.1836\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4768.8530 - mse: 4768.8530\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3987.5247 - mse: 3987.5247\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3328.8452 - mse: 3328.8452\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2790.1975 - mse: 2790.1975\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2333.0967 - mse: 2333.0967\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1927.9374 - mse: 1927.9374\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1577.1807 - mse: 1577.1807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 18:54:06.357399: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1283.0073 - mse: 1283.0073\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1038.4386 - mse: 1038.4386\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 827.8225 - mse: 827.8225\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 655.7411 - mse: 655.7411\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 518.8636 - mse: 518.8636\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 409.0315 - mse: 409.0315\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 327.1448 - mse: 327.1448\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 264.4889 - mse: 264.4889\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 218.5727 - mse: 218.5727\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 187.2056 - mse: 187.2056\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 165.5181 - mse: 165.5181\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 149.7897 - mse: 149.7897\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 139.2242 - mse: 139.2242\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 133.4695 - mse: 133.4695\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 130.5396 - mse: 130.5396\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 129.3627 - mse: 129.3627\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 128.5547 - mse: 128.5547\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 128.5036 - mse: 128.5036\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 127.5984 - mse: 127.5984\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 128.5592 - mse: 128.5592\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 128.1906 - mse: 128.1906\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 126.2007 - mse: 126.2007\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 125.4088 - mse: 125.4088\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 126.1662 - mse: 126.1662\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 128.3697 - mse: 128.3697\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 126.6232 - mse: 126.6232\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 128.3205 - mse: 128.3205\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 124.0650 - mse: 124.0650\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 122.0461 - mse: 122.0461\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 121.9900 - mse: 121.9900\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 120.3082 - mse: 120.3082\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 118.6197 - mse: 118.6197\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 117.4199 - mse: 117.4199\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 118.4606 - mse: 118.4606\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 122.7273 - mse: 122.7273\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 119.5683 - mse: 119.5683\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 114.2953 - mse: 114.2953\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 118.2261 - mse: 118.2261\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 112.5667 - mse: 112.5667\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 112.3719 - mse: 112.3719\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 110.7343 - mse: 110.7343\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 107.8653 - mse: 107.8653\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 118.4258 - mse: 118.4258\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 113.8050 - mse: 113.8050\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 110.2746 - mse: 110.2746\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 106.7505 - mse: 106.7505\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 116.8935 - mse: 116.8935\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 105.9302 - mse: 105.9302\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 102.7318 - mse: 102.7318\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 101.7709 - mse: 101.7709\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 101.0065 - mse: 101.0065\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 104.5310 - mse: 104.5310\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 101.5771 - mse: 101.5771\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 97.4742 - mse: 97.4742\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 106.8440 - mse: 106.8440\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 99.3477 - mse: 99.3477\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 99.4480 - mse: 99.4480\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 104.0527 - mse: 104.0527\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 96.0377 - mse: 96.0377\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 96.3753 - mse: 96.3753\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 92.4078 - mse: 92.4078\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 92.2670 - mse: 92.2670\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 91.4398 - mse: 91.4398\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 91.2847 - mse: 91.2847\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 88.6149 - mse: 88.6149\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 95.6820 - mse: 95.6820\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 89.7059 - mse: 89.7059\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 88.8184 - mse: 88.8184\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 93.0182 - mse: 93.0182\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 85.1761 - mse: 85.1761\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 82.4189 - mse: 82.4189\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 82.3168 - mse: 82.3168\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 81.2771 - mse: 81.2771\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 81.8995 - mse: 81.8995\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 85.1900 - mse: 85.1900\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 82.3150 - mse: 82.3150\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 85.6251 - mse: 85.6251\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 82.6065 - mse: 82.6065\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 80.4471 - mse: 80.4471\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 76.8349 - mse: 76.8349\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 75.6635 - mse: 75.6635\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 77.7273 - mse: 77.7273\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 76.6456 - mse: 76.6456\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 77.4817 - mse: 77.4817\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 73.4636 - mse: 73.4636\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 79.8915 - mse: 79.8915\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 75.3414 - mse: 75.3414\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 70.0610 - mse: 70.0610\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 68.1537 - mse: 68.1537\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 72.4548 - mse: 72.4548\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 71.9980 - mse: 71.9980\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 77.3315 - mse: 77.3315\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 69.2066 - mse: 69.2066\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 69.4894 - mse: 69.4894\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 65.6468 - mse: 65.6468\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 67.4481 - mse: 67.4481\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 65.8719 - mse: 65.8719\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 74.7427 - mse: 74.7427\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 70.7491 - mse: 70.7491\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 70.3031 - mse: 70.3031\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 65.0124 - mse: 65.0124\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 64.7427 - mse: 64.7427\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 61.5259 - mse: 61.5259\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 65.1437 - mse: 65.1437\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 63.0524 - mse: 63.0524\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 60.5040 - mse: 60.5040\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 57.7321 - mse: 57.7321\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 59.8280 - mse: 59.8280\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 61.1511 - mse: 61.1511\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 58.2275 - mse: 58.2275\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 71.0542 - mse: 71.0542\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 57.0757 - mse: 57.0757\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 55.4123 - mse: 55.4123\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 54.8013 - mse: 54.8013\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 55.5499 - mse: 55.5499\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 61.2177 - mse: 61.2177\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 56.0211 - mse: 56.0211\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 52.7786 - mse: 52.7786\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 54.4810 - mse: 54.4810\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 53.5315 - mse: 53.5315\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 55.9447 - mse: 55.9447\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 60.2258 - mse: 60.2258\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 56.4112 - mse: 56.4112\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 49.2563 - mse: 49.2563\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 48.7363 - mse: 48.7363\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 48.9306 - mse: 48.9306\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 48.8872 - mse: 48.8872\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 53.0448 - mse: 53.0448\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 46.6693 - mse: 46.6693\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 46.9849 - mse: 46.9849\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 50.7987 - mse: 50.7987\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 45.0047 - mse: 45.0047\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 48.8123 - mse: 48.8123\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 65.1588 - mse: 65.1588\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 48.5543 - mse: 48.5543\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 46.2655 - mse: 46.2655\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 46.8711 - mse: 46.8711\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 48.9031 - mse: 48.9031\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 54.6794 - mse: 54.6794\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 44.5413 - mse: 44.5413\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 41.9561 - mse: 41.9561\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 41.2103 - mse: 41.2103\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 41.7894 - mse: 41.7894\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 41.0465 - mse: 41.0465\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 41.6151 - mse: 41.6151\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 39.9568 - mse: 39.9568\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 39.3604 - mse: 39.3604\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 39.7586 - mse: 39.7586\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 38.2003 - mse: 38.2003\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 49.7732 - mse: 49.7732\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 41.8628 - mse: 41.8628\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 36.9889 - mse: 36.9889\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 36.0815 - mse: 36.0815\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 35.8724 - mse: 35.8724\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 36.1161 - mse: 36.1161\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 34.9057 - mse: 34.9057\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 37.3710 - mse: 37.3710\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 36.2168 - mse: 36.2168\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 36.1143 - mse: 36.1143\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 41.0574 - mse: 41.0574\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 42.3189 - mse: 42.3189\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 32.3184 - mse: 32.3184\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 31.7486 - mse: 31.7486\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 31.3398 - mse: 31.3398\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 35.7064 - mse: 35.7064\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 32.3046 - mse: 32.3046\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 30.4417 - mse: 30.4417\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 32.1136 - mse: 32.1136\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 42.8987 - mse: 42.8987\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 30.9421 - mse: 30.9421\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 32.3940 - mse: 32.3940\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 28.5618 - mse: 28.5618\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 28.4830 - mse: 28.4830\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 28.1767 - mse: 28.1767\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 32.0486 - mse: 32.0486\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 27.3789 - mse: 27.3789\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 27.1600 - mse: 27.1600\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 31.9117 - mse: 31.9117\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 27.6929 - mse: 27.6929\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 29.8738 - mse: 29.8738\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.7688 - mse: 27.7688\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.1359 - mse: 26.1359\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.4295 - mse: 25.4295\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 27.2970 - mse: 27.2970\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 41.9524 - mse: 41.9524\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.6727 - mse: 30.6727\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.5257 - mse: 25.5257\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.8344 - mse: 23.8344\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 23.7804 - mse: 23.7804\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.0124 - mse: 24.0124\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.2738 - mse: 23.2738\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 28.6329 - mse: 28.6329\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.4791 - mse: 25.4791\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.9036 - mse: 30.9036\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 26.9694 - mse: 26.9694\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 21.7811 - mse: 21.7811\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.3736 - mse: 21.3736\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.9693 - mse: 22.9693\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.3844 - mse: 24.3844\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.8765 - mse: 22.8765\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.8309 - mse: 21.8309\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.7553 - mse: 20.7553\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.7901 - mse: 22.7901\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.0090 - mse: 26.0090\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 23.8686 - mse: 23.8686\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.4318 - mse: 22.4318\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.6064 - mse: 19.6064\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.9969 - mse: 23.9969\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.8779 - mse: 18.8779\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.3310 - mse: 20.3310\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.5426 - mse: 18.5426\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.8429 - mse: 19.8429\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.7574 - mse: 17.7574\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.1878 - mse: 20.1878\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.4145 - mse: 22.4145\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.0888 - mse: 17.0888\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.8780 - mse: 16.8780\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.5353 - mse: 21.5353\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.1791 - mse: 27.1791\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.4238 - mse: 16.4238\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.3797 - mse: 19.3797\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.1903 - mse: 17.1903\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.9004 - mse: 15.9004\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.8295 - mse: 15.8295\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.4229 - mse: 15.4229\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.1718 - mse: 17.1718\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.1946 - mse: 16.1946\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.7112 - mse: 28.7112\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.9480 - mse: 18.9480\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.7631 - mse: 15.7631\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.4662 - mse: 14.4662\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.6749 - mse: 14.6749\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.5895 - mse: 15.5895\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.1339 - mse: 17.1339\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.4057 - mse: 14.4057\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.7344 - mse: 15.7344\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.9866 - mse: 18.9866\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.0603 - mse: 16.0603\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.2186 - mse: 16.2186\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.7210 - mse: 14.7210\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.9596 - mse: 16.9596\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.1374 - mse: 18.1374\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.7390 - mse: 17.7390\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.5808 - mse: 19.5808\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9049 - mse: 12.9049\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.4420 - mse: 12.4420\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.6323 - mse: 13.6323\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.3414 - mse: 12.3414\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.8635 - mse: 13.8635\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.4798 - mse: 13.4798\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.8851 - mse: 11.8851\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.2789 - mse: 15.2789\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.0345 - mse: 12.0345\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.1940 - mse: 12.1940\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.5594 - mse: 14.5594\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.7425 - mse: 18.7425\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1486 - mse: 11.1486\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.3791 - mse: 11.3791\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.9979 - mse: 10.9979\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.0095 - mse: 11.0095\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.5374 - mse: 15.5374\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 20.0302 - mse: 20.0302\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 11.1478 - mse: 11.1478\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.5935 - mse: 10.5935\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.4372 - mse: 12.4372\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.7749 - mse: 11.7749\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.2637 - mse: 11.2637\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.3003 - mse: 21.3003\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.1098 - mse: 18.1098\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.0579 - mse: 12.0579\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0964 - mse: 10.0964\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7859 - mse: 9.7859\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.1384 - mse: 12.1384\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.3744 - mse: 14.3744\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 10.3437 - mse: 10.3437\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.5465 - mse: 9.5465\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.9278 - mse: 10.9278\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.2331 - mse: 16.2331\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9490 - mse: 12.9490\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0969 - mse: 11.0969\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8994 - mse: 8.8994\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8297 - mse: 8.8297\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.3762 - mse: 9.3762\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.2925 - mse: 14.2925\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.1556 - mse: 13.1556\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8058 - mse: 8.8058\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4908 - mse: 9.4908\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.2856 - mse: 10.2856\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.7096 - mse: 11.7096\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.7978 - mse: 15.7978\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.1916 - mse: 12.1916\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5447 - mse: 8.5447\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.9895 - mse: 7.9895\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.2140 - mse: 8.2140\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.9910 - mse: 8.9910\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.6749 - mse: 14.6749\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.8537 - mse: 7.8537\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6495 - mse: 7.6495\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1398 - mse: 11.1398\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.0971 - mse: 10.0971\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.5036 - mse: 7.5036\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.8153 - mse: 11.8153\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.2639 - mse: 14.2639\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.7685 - mse: 10.7685\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.4812 - mse: 7.4812\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1928 - mse: 7.1928\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.2723 - mse: 8.2723\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8658 - mse: 8.8658\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.6021 - mse: 8.6021\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.8166 - mse: 11.8166\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.8982 - mse: 8.8982\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6429 - mse: 8.6429\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.3543 - mse: 11.3543\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.9482 - mse: 6.9482\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4734 - mse: 11.4734\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.3029 - mse: 11.3029\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.1027 - mse: 7.1027\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.5809 - mse: 6.5809\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2112 - mse: 7.2112\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.3599 - mse: 10.3599\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.0640 - mse: 13.0640\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.3872 - mse: 12.3872\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4758 - mse: 8.4758\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.7252 - mse: 6.7252\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.2488 - mse: 6.2488\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.3806 - mse: 6.3806\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.0381 - mse: 8.0381\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0082 - mse: 11.0082\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3342 - mse: 8.3342\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2962 - mse: 10.2962\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1067 - mse: 10.1067\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.8848 - mse: 5.8848\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.6381 - mse: 6.6381\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8409 - mse: 10.8409\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.5721 - mse: 8.5721\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.8179 - mse: 7.8179\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.9691 - mse: 5.9691\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.8520 - mse: 6.8520\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2761 - mse: 7.2761\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.7321 - mse: 8.7321\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.2444 - mse: 8.2444\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.5263 - mse: 6.5263\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.7374 - mse: 6.7374\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7817 - mse: 8.7817\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.7977 - mse: 5.7977\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.5891 - mse: 5.5891\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.8432 - mse: 5.8432\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.2732 - mse: 5.2732\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.4513 - mse: 5.4513\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.0320 - mse: 14.0320\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.8842 - mse: 11.8842\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.2171 - mse: 5.2171\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.3874 - mse: 7.3874\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.6656 - mse: 7.6656\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2803 - mse: 7.2803\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.1787 - mse: 5.1787\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.2970 - mse: 6.2970\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0941 - mse: 10.0941\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4917 - mse: 8.4917\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6014 - mse: 7.6014\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.9214 - mse: 4.9214\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.4919 - mse: 5.4919\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.2652 - mse: 6.2652\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.3096 - mse: 10.3096\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.8486 - mse: 4.8486\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.6464 - mse: 5.6464\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.7581 - mse: 4.7581\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.8175 - mse: 4.8175\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.2764 - mse: 6.2764\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.9616 - mse: 11.9616\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.3173 - mse: 7.3173\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.0886 - mse: 5.0886\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.0419 - mse: 5.0419\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1067 - mse: 7.1067\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.4329 - mse: 12.4329\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.2037 - mse: 5.2037\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.5114 - mse: 4.5114\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.6321 - mse: 6.6321\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.2101 - mse: 6.2101\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.5063 - mse: 5.5063\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.2184 - mse: 8.2184\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5197 - mse: 8.5197\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.4345 - mse: 4.4345\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.3131 - mse: 4.3131\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.2680 - mse: 5.2680\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7531 - mse: 9.7531\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.2729 - mse: 9.2729\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.4737 - mse: 4.4737\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.2763 - mse: 4.2763\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.5330 - mse: 5.5330\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.2888 - mse: 5.2888\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.5610 - mse: 7.5610\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8425 - mse: 8.8425\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.8885 - mse: 5.8885\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.8081 - mse: 4.8081\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.0602 - mse: 4.0602\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1215 - mse: 4.1215\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.7131 - mse: 4.7131\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3066 - mse: 8.3066\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9646 - mse: 10.9646\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.0598 - mse: 5.0598\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.0182 - mse: 5.0182\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5820 - mse: 11.5820\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.3252 - mse: 10.3252\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.9647 - mse: 4.9647\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.9876 - mse: 4.9876\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 4.9637 - mse: 4.9637\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.8697 - mse: 3.8697\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.8703 - mse: 6.8703\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.8648 - mse: 8.8648\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.7864 - mse: 8.7864\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.4706 - mse: 6.4706\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.4092 - mse: 4.4092\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1815 - mse: 4.1815\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.9759 - mse: 3.9759\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.6529 - mse: 4.6529\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.7913 - mse: 6.7913\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.4509 - mse: 8.4509\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.7592 - mse: 3.7592\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.9434 - mse: 3.9434\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.5216 - mse: 4.5216\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.0834 - mse: 9.0834\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1634 - mse: 10.1634\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.1164 - mse: 5.1164\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.6340 - mse: 3.6340\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.2854 - mse: 4.2854\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.7451 - mse: 3.7451\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.5175 - mse: 3.5175\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.3929 - mse: 4.3929\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4638 - mse: 10.4638\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.4997 - mse: 7.4997\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1777 - mse: 4.1777\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.6080 - mse: 5.6080\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0588 - mse: 7.0588\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.8478 - mse: 4.8478\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.2472 - mse: 4.2472\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.2385 - mse: 5.2385\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.8239 - mse: 6.8239\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.5225 - mse: 5.5225\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.4289 - mse: 3.4289\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5337 - mse: 1.533 - 0s 6ms/step - loss: 3.4006 - mse: 3.4006\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.6658 - mse: 5.6658\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9738 - mse: 12.9738\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6878 - mse: 9.6878\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.8877 - mse: 3.8877\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.4019 - mse: 3.4019\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2816 - mse: 3.2816\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2992 - mse: 3.2992\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3064 - mse: 3.3064\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.2506 - mse: 3.2506\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.0441 - mse: 4.0441\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.2053 - mse: 7.2053\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.5404 - mse: 12.5404\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.2751 - mse: 4.2751\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2618 - mse: 3.2618\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.7062 - mse: 3.7062\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.8012 - mse: 3.8012\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 3.9455 - mse: 3.9455\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.7982 - mse: 5.7982\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.1041 - mse: 8.1041\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.0592 - mse: 7.0592\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.6524 - mse: 5.6524\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.0401 - mse: 4.0401\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2527 - mse: 3.2527\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.2416 - mse: 3.2416\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0759 - mse: 3.0759\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.2302 - mse: 5.2302\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.4525 - mse: 10.4525\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3194 - mse: 3.3194\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3081 - mse: 3.3081\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0901 - mse: 3.0901\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0125 - mse: 3.0125\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.9698 - mse: 2.9698\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3408 - mse: 8.3408\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.3598 - mse: 13.3598\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.7936 - mse: 3.7936\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.2179 - mse: 3.2179\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.0062 - mse: 4.0062\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1607 - mse: 4.1607\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.0445 - mse: 3.0445\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.8203 - mse: 4.8203\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.9878 - mse: 4.9878\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.0893 - mse: 4.0893\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1846 - mse: 4.1846\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.4681 - mse: 6.4681\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6239 - mse: 9.6239\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.5056 - mse: 3.5056\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.9241 - mse: 2.9241\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8889 - mse: 2.8889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15e063b20>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.67401975,  0.01203257,  0.39865106],\n",
       "        [ 0.22308682, -0.46983638,  0.5329334 ],\n",
       "        [ 0.37956527,  0.53532845, -0.23622927],\n",
       "        [-0.41672984,  0.97656095, -0.43376473],\n",
       "        [-0.20253417,  0.5411604 ,  0.685938  ],\n",
       "        [-0.20973827, -0.22960497, -0.63407093]], dtype=float32),\n",
       " array([ 0.11374736,  0.11315627, -0.1142685 ], dtype=float32),\n",
       " array([[ 0.49160755],\n",
       "        [ 0.65653884],\n",
       "        [-0.3687637 ]], dtype=float32),\n",
       " array([0.11356481], dtype=float32)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x15c8f5f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 18:54:20.215466: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>18.988573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>20.494436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>20.179680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>24.055197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>12.080913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8   18.988573\n",
       "AK       18.1   20.494436\n",
       "AZ       18.6   20.179680\n",
       "AR       22.4   24.055197\n",
       "CA       12.0   12.080913"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9089440360749013"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with the Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=558\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=558\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `sigmoid` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:04:03.606252: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15fb090a0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:04:10.589808: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "      <th>pred_sigmoid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros  pred_sigmoid\n",
       "abbrev                                 \n",
       "AL       18.8         1.0           1.0\n",
       "AK       18.1         1.0           1.0\n",
       "AZ       18.6         1.0           1.0\n",
       "AR       22.4         1.0           1.0\n",
       "CA       12.0         1.0           1.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres['pred_sigmoid'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235.4076470588235"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fit()` the `model` and compare again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 243.7578 - mse: 243.7578"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 15:58:11.147593: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4076\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4077\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4076\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4076\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4076\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ae12f730>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.10580671,  0.7500808 ,  0.16253507],\n",
       "        [-0.34526154, -0.5762522 , -0.7753689 ],\n",
       "        [-0.29335958, -0.2159903 , -0.16609263],\n",
       "        [ 0.26099467,  0.28944385, -0.42102963],\n",
       "        [-0.25016683,  0.3994559 , -0.5259208 ],\n",
       "        [ 0.22661805,  0.02153301,  0.28560925]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[-1.1483067 ],\n",
       "        [-0.9938561 ],\n",
       "        [-0.47182316]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 15:58:17.169034: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8         1.0\n",
       "AK       18.1         1.0\n",
       "AZ       18.6         1.0\n",
       "AR       22.4         1.0\n",
       "CA       12.0         1.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235.4076470588235"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `linear` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:06:38.016567: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16a0211f0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:06:43.422516: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "      <th>pred_sigmoid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.594013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.238089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.742601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.711784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.716588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros  pred_sigmoid\n",
       "abbrev                                 \n",
       "AL       18.8         1.0     17.594013\n",
       "AK       18.1         1.0     17.238089\n",
       "AZ       18.6         1.0     17.742601\n",
       "AR       22.4         1.0     22.711784\n",
       "CA       12.0         1.0     11.716588"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres['pred_sigmoid'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235.4076470588235"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.34451395, -0.16314414, -0.20206104],\n",
       "        [-0.6177763 ,  0.5099444 , -0.4447385 ],\n",
       "        [-0.69090617,  0.5364897 ,  0.19511676],\n",
       "        [-0.3502738 ,  0.6438615 ,  0.8683041 ],\n",
       "        [ 0.32621065,  0.10962319, -0.14200883],\n",
       "        [-0.42247236,  0.10126512, -0.56384903]], dtype=float32),\n",
       " array([-0.18409787,  0.18990237,  0.1837502 ], dtype=float32),\n",
       " array([[-0.11881167],\n",
       "        [ 0.57659256],\n",
       "        [ 0.18077397]], dtype=float32),\n",
       " array([0.18946521], dtype=float32)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:07:23.995965: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>17.594013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>17.238089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>17.742601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>22.711784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>11.716588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8   17.594013\n",
       "AK       18.1   17.238089\n",
       "AZ       18.6   17.742601\n",
       "AR       22.4   22.711784\n",
       "CA       12.0   11.716588"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9834952454696326"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `tanh` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:08:46.666148: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16b8c52e0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:08:50.996101: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "      <th>pred_sigmoid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>17.594013</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>17.238089</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>17.742601</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>22.711784</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>11.716588</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros  pred_sigmoid\n",
       "abbrev                                 \n",
       "AL       18.8   17.594013           1.0\n",
       "AK       18.1   17.238089           1.0\n",
       "AZ       18.6   17.742601           1.0\n",
       "AR       22.4   22.711784           1.0\n",
       "CA       12.0   11.716588           1.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres['pred_sigmoid'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9834952454696326"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.5778661 ,  0.25024602,  1.017356  ],\n",
       "        [ 1.5251609 , -0.07253256,  0.45896563],\n",
       "        [ 0.9107427 , -0.14757796,  0.8263705 ],\n",
       "        [ 1.1551406 ,  0.5162253 ,  1.0961491 ],\n",
       "        [ 1.3419919 ,  0.8816063 ,  1.4884272 ],\n",
       "        [ 1.5800475 ,  1.1244183 ,  1.560878  ]], dtype=float32),\n",
       " array([0.9818366 , 0.4632104 , 0.99483544], dtype=float32),\n",
       " array([[1.3824977],\n",
       "        [0.7467232],\n",
       "        [2.0802624]], dtype=float32),\n",
       " array([0.9798329], dtype=float32)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8         1.0\n",
       "AK       18.1         1.0\n",
       "AZ       18.6         1.0\n",
       "AR       22.4         1.0\n",
       "CA       12.0         1.0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235.4076488219523"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `relu` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.80496716,  0.7598734 , -0.42897052],\n",
       "        [ 0.10918653,  0.00948036, -0.10976821],\n",
       "        [ 0.21171498,  0.0022319 , -0.33985347],\n",
       "        [-0.3171079 ,  0.52273583,  0.29848576],\n",
       "        [-0.5062138 , -0.0099631 ,  0.14785284],\n",
       "        [-0.7037198 ,  0.5692266 , -0.36761624]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[ 0.14850485],\n",
       "        [-0.22410452],\n",
       "        [-1.160273  ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:13:39.599849: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1771c1520>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:13:46.291190: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "      <th>pred_sigmoid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros  pred_sigmoid\n",
       "abbrev                                 \n",
       "AL       18.8         0.0           0.0\n",
       "AK       18.1         0.0           0.0\n",
       "AZ       18.6         0.0           0.0\n",
       "AR       22.4         0.0           0.0\n",
       "CA       12.0         0.0           0.0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres['pred_sigmoid'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265.9880392156863"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.80496716,  0.7598734 , -0.42897052],\n",
       "        [ 0.10918653,  0.00948036, -0.10976821],\n",
       "        [ 0.21171498,  0.0022319 , -0.33985347],\n",
       "        [-0.3171079 ,  0.52273583,  0.29848576],\n",
       "        [-0.5062138 , -0.0099631 ,  0.14785284],\n",
       "        [-0.7037198 ,  0.5692266 , -0.36761624]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[ 0.14850485],\n",
       "        [-0.22410452],\n",
       "        [-1.160273  ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8         0.0\n",
       "AK       18.1         0.0\n",
       "AZ       18.6         0.0\n",
       "AR       22.4         0.0\n",
       "CA       12.0         0.0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265.9880392156863"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How are the predictions changing? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizers comparison in GIF ‚Üí https://mlfromscratch.com/optimizers-explained/#adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tesla's Neural Network Models is composed of 48 models trainned in 70.000 hours of GPU ‚Üí https://tesla.com/ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Year with a 8 GPU Computer ‚Üí https://twitter.com/thirdrowtesla/status/1252723358342377472"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Gradient Descent `SGD`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile & Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.3939669 ,  0.49886513,  0.5103427 ],\n",
       "        [ 0.03351152,  0.36945796,  0.47778463],\n",
       "        [ 0.7332885 ,  0.5005772 ,  0.49273205],\n",
       "        [-0.0714227 , -0.67955977, -0.37271243],\n",
       "        [ 0.05672973,  0.5415263 , -0.16182244],\n",
       "        [ 0.5573889 , -0.20461315, -0.33603796]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[-0.11912215],\n",
       "        [ 1.1910547 ],\n",
       "        [ 1.0008725 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:25:51.663632: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-11-17 19:25:51.764682: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=500, verbose=0, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan]], dtype=float32),\n",
       " array([nan, nan, nan], dtype=float32),\n",
       " array([[nan],\n",
       "        [nan],\n",
       "        [nan]], dtype=float32),\n",
       " array([nan], dtype=float32)]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:26:09.457302: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8         NaN\n",
       "AK       18.1         NaN\n",
       "AZ       18.6         NaN\n",
       "AR       22.4         NaN\n",
       "CA       12.0         NaN"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### View History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `ADAM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FL</th>\n",
       "      <td>17.9</td>\n",
       "      <td>3.759</td>\n",
       "      <td>5.191</td>\n",
       "      <td>16.468</td>\n",
       "      <td>16.826</td>\n",
       "      <td>1160.13</td>\n",
       "      <td>144.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA</th>\n",
       "      <td>8.2</td>\n",
       "      <td>1.886</td>\n",
       "      <td>2.870</td>\n",
       "      <td>7.134</td>\n",
       "      <td>6.560</td>\n",
       "      <td>1011.14</td>\n",
       "      <td>135.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT</th>\n",
       "      <td>13.6</td>\n",
       "      <td>4.080</td>\n",
       "      <td>4.080</td>\n",
       "      <td>13.056</td>\n",
       "      <td>12.920</td>\n",
       "      <td>716.20</td>\n",
       "      <td>109.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX</th>\n",
       "      <td>19.4</td>\n",
       "      <td>7.760</td>\n",
       "      <td>7.372</td>\n",
       "      <td>17.654</td>\n",
       "      <td>16.878</td>\n",
       "      <td>1004.75</td>\n",
       "      <td>156.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NC</th>\n",
       "      <td>16.8</td>\n",
       "      <td>6.552</td>\n",
       "      <td>5.208</td>\n",
       "      <td>15.792</td>\n",
       "      <td>13.608</td>\n",
       "      <td>708.24</td>\n",
       "      <td>127.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                       \n",
       "FL       17.9     3.759    5.191          16.468       16.826      1160.13   \n",
       "MA        8.2     1.886    2.870           7.134        6.560      1011.14   \n",
       "VT       13.6     4.080    4.080          13.056       12.920       716.20   \n",
       "TX       19.4     7.760    7.372          17.654       16.878      1004.75   \n",
       "NC       16.8     6.552    5.208          15.792       13.608       708.24   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "FL          144.18  \n",
       "MA          135.63  \n",
       "VT          109.61  \n",
       "TX          156.83  \n",
       "NC          127.82  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset(name='car_crashes', index_col='abbrev')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Concepts in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_intercept': True,\n",
       " 'normalize': 'deprecated',\n",
       " 'copy_X': True,\n",
       " 'n_jobs': None,\n",
       " 'positive': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_intercept': True,\n",
       " 'normalize': 'deprecated',\n",
       " 'copy_X': True,\n",
       " 'n_jobs': None,\n",
       " 'positive': False,\n",
       " 'feature_names_in_': array(['speeding', 'alcohol', 'not_distracted', 'no_previous',\n",
       "        'ins_premium', 'ins_losses'], dtype=object),\n",
       " 'n_features_in_': 6,\n",
       " 'coef_': array([-0.02650334,  0.49252176,  0.17453205,  0.71257329, -0.00125105,\n",
       "         0.00643096]),\n",
       " '_residues': 35.75599620119316,\n",
       " 'rank_': 6,\n",
       " 'singular_': array([1265.56295658,  136.88075844,   40.51113699,   14.55337989,\n",
       "          10.99084201,    6.16130337]),\n",
       " 'intercept_': 1.4120634209126202}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_48148/3324602025.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fit' is not defined"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'algo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_48148/22777151.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'algo' is not defined"
     ]
    }
   ],
   "source": [
    "algo.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`algo = ?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_48148/861900531.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "algo = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.5440465 , -0.5944887 ,  0.1894604 ],\n",
       "        [-0.39043406,  0.19923973,  0.01172954],\n",
       "        [-0.12323105,  0.02964735, -0.58172023],\n",
       "        [ 0.65388715,  0.4604026 , -0.01621622],\n",
       "        [ 0.32393718, -0.31059176,  0.5557525 ],\n",
       "        [ 0.29998815,  0.30244648,  0.5110692 ]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[0.18368232],\n",
       "        [0.8821639 ],\n",
       "        [1.0883535 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adadelta', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')\n",
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:30:47.771781: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-11-17 19:30:48.001326: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=500, verbose=0, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.5420204 , -0.5965248 ,  0.1874278 ],\n",
       "        [-0.39250568,  0.19715802,  0.00965102],\n",
       "        [-0.12528914,  0.02757989, -0.5837849 ],\n",
       "        [ 0.65183276,  0.45833814, -0.01827728],\n",
       "        [ 0.32192993, -0.31260893,  0.55373853],\n",
       "        [ 0.29795647,  0.30040556,  0.5090314 ]], dtype=float32),\n",
       " array([-0.00209766, -0.00210741, -0.00210438], dtype=float32),\n",
       " array([[0.1816623 ],\n",
       "        [0.88417244],\n",
       "        [1.0863386 ]], dtype=float32),\n",
       " array([-0.00210574], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:30:58.155570: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>422.732758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>518.131470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>439.598328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>438.806305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>479.433990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8  422.732758\n",
       "AK       18.1  518.131470\n",
       "AZ       18.6  439.598328\n",
       "AR       22.4  438.806305\n",
       "CA       12.0  479.433990"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200408.45796179184"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### View History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `RMSPROP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does it take different times to get the best accuracy? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `loss` Function Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `activation` Function Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Number of `epochs` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `optimizer` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `kernel_initializer` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The number of Neurons & Hidden Layers\n",
    "\n",
    "> Why Deep Learning?\n",
    ">\n",
    "> - Non-lineality patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/beginners-ask-how-many-hidden-layers-neurons-to-use-in-artificial-neural-networks-51466afa0d3e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.87287&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Mathematical Formula\n",
    "- Weights / Kernel Initializer\n",
    "- Loss Function\n",
    "- Activation Function\n",
    "- Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What cannot you change arbitrarily of a Neural Network?\n",
    "\n",
    "- Input Neurons\n",
    "- Output Neurons\n",
    "- Loss Functions\n",
    "- Activation Functions"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Jes√∫s L√≥pez @sotastica"
   }
  ],
  "kernelspec": {
   "display_name": "DeepLearning Python",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
