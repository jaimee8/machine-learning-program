{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+5\">#07. Why Neural Networks Deeply Learn a Mathematical Formula?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Book + Private Lessons [Here ‚Üó](https://sotastica.com/reservar)\n",
    "- Subscribe to my [Blog ‚Üó](https://blog.pythonassembly.com/)\n",
    "- Let's keep in touch on [LinkedIn ‚Üó](www.linkedin.com/in/jsulopz) üòÑ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Machine Learning, what does it mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - The Machine Learns...\n",
    ">\n",
    "> But, **what does it learn?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Machine Learning, what does it mean? ‚èØ<br><br>¬∑ The machine learns...<br><br>Ha ha, not funny! ü§® What does it learn?<br><br>¬∑ A mathematical equation. For example: <a href=\"https://t.co/sjtq9F2pq7\">pic.twitter.com/sjtq9F2pq7</a></p>&mdash; Jes√∫s L√≥pez (@sotastica) <a href=\"https://twitter.com/sotastica/status/1449735653328031745?ref_src=twsrc%5Etfw\">October 17, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Machine Learning, what does it mean? ‚èØ<br><br>¬∑ The machine learns...<br><br>Ha ha, not funny! ü§® What does it learn?<br><br>¬∑ A mathematical equation. For example: <a href=\"https://t.co/sjtq9F2pq7\">pic.twitter.com/sjtq9F2pq7</a></p>&mdash; Jes√∫s L√≥pez (@sotastica) <a href=\"https://twitter.com/sotastica/status/1449735653328031745?ref_src=twsrc%5Etfw\">October 17, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does the Machine Learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In a Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Ht3rYS-JilE\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Ht3rYS-JilE\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=329\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=329\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Practical Example ‚Üí [Tesla Autopilot](https://www.tesla.com/AI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Example where It Fails ‚Üí [Tesla Confuses Moon with Semaphore](https://twitter.com/Carnage4Life/status/1418920100086784000?s=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Simply execute the following lines of code to load the data.\n",
    "> - This dataset contains **statistics about Car Accidents** (columns)\n",
    "> - In each one of **USA States** (rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/fivethirtyeight/fivethirtyeight-bad-drivers-dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MO</th>\n",
       "      <td>16.1</td>\n",
       "      <td>6.923</td>\n",
       "      <td>5.474</td>\n",
       "      <td>14.812</td>\n",
       "      <td>13.524</td>\n",
       "      <td>790.32</td>\n",
       "      <td>144.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CT</th>\n",
       "      <td>10.8</td>\n",
       "      <td>4.968</td>\n",
       "      <td>3.888</td>\n",
       "      <td>9.396</td>\n",
       "      <td>8.856</td>\n",
       "      <td>1068.73</td>\n",
       "      <td>167.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MI</th>\n",
       "      <td>14.1</td>\n",
       "      <td>3.384</td>\n",
       "      <td>3.948</td>\n",
       "      <td>13.395</td>\n",
       "      <td>10.857</td>\n",
       "      <td>1110.61</td>\n",
       "      <td>152.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UT</th>\n",
       "      <td>11.3</td>\n",
       "      <td>4.859</td>\n",
       "      <td>1.808</td>\n",
       "      <td>9.944</td>\n",
       "      <td>10.848</td>\n",
       "      <td>809.38</td>\n",
       "      <td>109.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KY</th>\n",
       "      <td>21.4</td>\n",
       "      <td>4.066</td>\n",
       "      <td>4.922</td>\n",
       "      <td>16.692</td>\n",
       "      <td>16.264</td>\n",
       "      <td>872.51</td>\n",
       "      <td>137.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                       \n",
       "MO       16.1     6.923    5.474          14.812       13.524       790.32   \n",
       "CT       10.8     4.968    3.888           9.396        8.856      1068.73   \n",
       "MI       14.1     3.384    3.948          13.395       10.857      1110.61   \n",
       "UT       11.3     4.859    1.808           9.944       10.848       809.38   \n",
       "KY       21.4     4.066    4.922          16.692       16.264       872.51   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "MO          144.45  \n",
       "CT          167.02  \n",
       "MI          152.26  \n",
       "UT          109.48  \n",
       "KY          137.13  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset(name='car_crashes', index_col='abbrev')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Concepts in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_intercept': True,\n",
       " 'normalize': 'deprecated',\n",
       " 'copy_X': True,\n",
       " 'n_jobs': None,\n",
       " 'positive': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_intercept': True,\n",
       " 'normalize': 'deprecated',\n",
       " 'copy_X': True,\n",
       " 'n_jobs': None,\n",
       " 'positive': False,\n",
       " 'feature_names_in_': array(['speeding', 'alcohol', 'not_distracted', 'no_previous',\n",
       "        'ins_premium', 'ins_losses'], dtype=object),\n",
       " 'n_features_in_': 6,\n",
       " 'coef_': array([-0.02650334,  0.49252176,  0.17453205,  0.71257329, -0.00125105,\n",
       "         0.00643096]),\n",
       " '_residues': 35.75599620119316,\n",
       " 'rank_': 6,\n",
       " 'singular_': array([1265.56295658,  136.88075844,   40.51113699,   14.55337989,\n",
       "          10.99084201,    6.16130337]),\n",
       " 'intercept_': 1.4120634209126202}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_48148/3324602025.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fit' is not defined"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'algo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_48148/22777151.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'algo' is not defined"
     ]
    }
   ],
   "source": [
    "algo.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`algo = ?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_48148/861900531.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "algo = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:27:10.338121: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-11-17 19:27:10.338206: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "algo = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>7.332</td>\n",
       "      <td>5.640</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.040</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>7.421</td>\n",
       "      <td>4.525</td>\n",
       "      <td>16.290</td>\n",
       "      <td>17.014</td>\n",
       "      <td>1053.48</td>\n",
       "      <td>133.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>6.510</td>\n",
       "      <td>5.208</td>\n",
       "      <td>15.624</td>\n",
       "      <td>17.856</td>\n",
       "      <td>899.47</td>\n",
       "      <td>110.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>4.032</td>\n",
       "      <td>5.824</td>\n",
       "      <td>21.056</td>\n",
       "      <td>21.280</td>\n",
       "      <td>827.34</td>\n",
       "      <td>142.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>4.200</td>\n",
       "      <td>3.360</td>\n",
       "      <td>10.920</td>\n",
       "      <td>10.680</td>\n",
       "      <td>878.41</td>\n",
       "      <td>165.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                       \n",
       "AL       18.8     7.332    5.640          18.048       15.040       784.55   \n",
       "AK       18.1     7.421    4.525          16.290       17.014      1053.48   \n",
       "AZ       18.6     6.510    5.208          15.624       17.856       899.47   \n",
       "AR       22.4     4.032    5.824          21.056       21.280       827.34   \n",
       "CA       12.0     4.200    3.360          10.920       10.680       878.41   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  \n",
       "AK          133.93  \n",
       "AZ          110.35  \n",
       "AR          142.39  \n",
       "CA          165.63  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Capa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_48148/3913913123.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCapa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCapa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Capa' is not defined"
     ]
    }
   ],
   "source": [
    "algo.add(layer=Capa(6))\n",
    "algo.add(layer=Capa(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the `Weights`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to `kernel_initializer` the weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "accidents = speeding \\cdot w_1 + alcohol \\cdot w_2 \\ + ... + \\ ins\\_losses \\cdot w_7\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='zeros'))\n",
    "model.add(layer=Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a Prediction with the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Can we make a prediction for for `Washington DC` accidents\n",
    "> - With the already initialized Mathematical Equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')\n",
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                \n",
       "AL         7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 18:44:21.544653: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-17 18:44:21.548214: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-11-17 18:44:21.594698: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(AL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[ 0.90974176],\n",
       "        [-0.0821209 ],\n",
       "        [ 0.70014215]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8         0.0\n",
       "AK       18.1         0.0\n",
       "AZ       18.6         0.0\n",
       "AR       22.4         0.0\n",
       "CA       12.0         0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265.9880392156863"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fit()` the `model` and compare again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 18:45:05.965242: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 213.8209 - mse: 213.8209\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 61.9320 - mse: 61.9320\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 34.2642 - mse: 34.2642\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.6045 - mse: 28.6045\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 27.6109 - mse: 27.6109\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 27.5657 - mse: 27.5657\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.9923 - mse: 26.9923\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 27.1784 - mse: 27.1784\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.6238 - mse: 26.6238\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.6339 - mse: 26.6339\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 26.6682 - mse: 26.6682\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.0386 - mse: 26.0386\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.4421 - mse: 25.4421\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.2147 - mse: 25.2147\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.1097 - mse: 25.1097\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.5557 - mse: 25.5557\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.7952 - mse: 24.7952\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.2347 - mse: 24.2347\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.3872 - mse: 26.3872\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.1348 - mse: 23.1348\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.0382 - mse: 24.0382\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.3327 - mse: 22.3327\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.1779 - mse: 24.1779\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.2001 - mse: 23.2001\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.1331 - mse: 21.1331\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.9769 - mse: 21.9769\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.6073 - mse: 23.6073\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.2133 - mse: 20.2133\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.4452 - mse: 21.4452\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.7510 - mse: 19.7510\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.4046 - mse: 19.4046\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.9807 - mse: 19.9807\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 22.0415 - mse: 22.0415\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 19.2141 - mse: 19.2141\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.2708 - mse: 18.2708\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.7747 - mse: 17.7747\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 19.1129 - mse: 19.1129\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.9143 - mse: 16.9143\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.7033 - mse: 16.7033\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.2487 - mse: 16.2487\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.9631 - mse: 16.9631\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.5066 - mse: 16.5066\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.6251 - mse: 21.6251\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.7355 - mse: 15.7355\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.7079 - mse: 16.7079\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.8134 - mse: 14.8134\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.4142 - mse: 14.4142\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 15.6307 - mse: 15.6307\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.8343 - mse: 14.8343\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.6300 - mse: 15.6300\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.3511 - mse: 13.3511\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.2818 - mse: 19.2818\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.1813 - mse: 16.1813\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.3776 - mse: 13.3776\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9006 - mse: 12.9006\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.3162 - mse: 12.3162\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.7359 - mse: 12.7359\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.0872 - mse: 14.0872\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.6619 - mse: 11.6619\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4994 - mse: 11.4994\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.6234 - mse: 12.6234\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1898 - mse: 11.1898\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.1457 - mse: 13.1457\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.4165 - mse: 13.4165\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.9977 - mse: 12.9977\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.0685 - mse: 12.0685\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8582 - mse: 10.8582\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.8253 - mse: 9.8253\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 10.0714 - mse: 10.0714\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.5291 - mse: 10.5291\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.1776 - mse: 9.1776\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.7285 - mse: 10.7285\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4755 - mse: 11.4755\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.9083 - mse: 9.9083\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.6149 - mse: 8.6149\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.2647 - mse: 9.2647\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.1836 - mse: 8.1836\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1778 - mse: 10.1778\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5671 - mse: 9.5671\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.7448 - mse: 7.7448\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9032 - mse: 7.9032\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1866 - mse: 10.1866\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.5872 - mse: 8.5872\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.9377 - mse: 7.9377\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4268 - mse: 8.4268\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2127 - mse: 7.2127\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.6170 - mse: 6.6170\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.4456 - mse: 6.4456\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.9613 - mse: 10.9613\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7819 - mse: 8.7819\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 6.7252 - mse: 6.7252\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.0358 - mse: 6.0358\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.3392 - mse: 6.3392\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 5.8511 - mse: 5.8511\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.7777 - mse: 5.7777\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.3654 - mse: 6.3654\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2532 - mse: 9.2532\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.1042 - mse: 8.1042\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1539 - mse: 7.1539\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.1430 - mse: 7.1430\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.6979 - mse: 5.6979\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.0222 - mse: 5.0222\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.2242 - mse: 5.2242\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.6462 - mse: 5.6462\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.3536 - mse: 7.3536\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.9346 - mse: 4.9346\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.8621 - mse: 4.8621\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.6096 - mse: 5.6096\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 6.0538 - mse: 6.0538\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.9376 - mse: 4.9376\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 6.1155 - mse: 6.1155\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.2115 - mse: 6.2115\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.1543 - mse: 4.1543\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.0766 - mse: 5.0766\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.2259 - mse: 7.2259\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 4.6681 - mse: 4.6681\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.1601 - mse: 5.1601\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 6.1131 - mse: 6.1131\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.6168 - mse: 4.6168\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.9167 - mse: 3.9167\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.9055 - mse: 3.9055\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.3448 - mse: 5.3448\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.1572 - mse: 5.1572\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.4769 - mse: 3.4769\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.3125 - mse: 4.3125\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.3521 - mse: 6.3521\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.4231 - mse: 4.4231\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 3.3598 - mse: 3.3598\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.7371 - mse: 3.7371\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.4886 - mse: 4.4886\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.3457 - mse: 4.3457\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.3594 - mse: 4.3594\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.0276 - mse: 3.0276\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.9846 - mse: 2.9846\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.9191 - mse: 2.9191\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8622 - mse: 2.8622\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.5708 - mse: 4.5708\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1145 - mse: 9.1145\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.8126 - mse: 3.8126\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7554 - mse: 2.7554\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8668 - mse: 2.8668\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.8954 - mse: 2.8954\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.9493 - mse: 2.9493\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.8909 - mse: 3.8909\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 5.3989 - mse: 5.3989\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.0712 - mse: 5.0712\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.5542 - mse: 2.5542\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3218 - mse: 3.3218\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.5612 - mse: 3.5612\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.6973 - mse: 4.6973\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.2913 - mse: 3.2913\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 2.4241 - mse: 2.4241\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.7295 - mse: 2.7295\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.4596 - mse: 3.4596\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.1079 - mse: 6.1079\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.4379 - mse: 6.4379\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.4221 - mse: 2.4221\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.2363 - mse: 3.2363\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3260 - mse: 2.3260\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 2.6898 - mse: 2.6898\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.9906 - mse: 3.9906\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 4.0427 - mse: 4.0427\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.9380 - mse: 2.9380\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.7955 - mse: 4.7955\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1715 - mse: 4.1715\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.9958 - mse: 2.9958\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.4229 - mse: 3.4229\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7102 - mse: 2.7102\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1363 - mse: 2.1363\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1853 - mse: 2.1853\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8545 - mse: 2.8545\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.0129 - mse: 2.0129\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.1715 - mse: 6.1715\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.5916 - mse: 5.5916\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0708 - mse: 2.0708\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8533 - mse: 2.8533\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2775 - mse: 3.2775\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0945 - mse: 3.0945\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.1094 - mse: 6.1094\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.3840 - mse: 4.3840\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3606 - mse: 2.3606\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9779 - mse: 1.9779\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.2305 - mse: 2.2305\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7695 - mse: 2.7695\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.9776 - mse: 3.9776\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.9187 - mse: 4.9187\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.5276 - mse: 3.5276\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3781 - mse: 2.3781\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.0470 - mse: 3.0470\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3890 - mse: 2.3890\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8999 - mse: 1.8999\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.8841 - mse: 1.8841\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.6904 - mse: 3.6904\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.7296 - mse: 5.7296\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2837 - mse: 3.2837\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9034 - mse: 1.9034\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2040 - mse: 2.2040\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8989 - mse: 1.8989\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.3554 - mse: 4.3554\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.0662 - mse: 6.0662\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.6914 - mse: 2.6914\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8131 - mse: 1.8131\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8099 - mse: 1.8099\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.7889 - mse: 2.7889\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.3410 - mse: 4.3410\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.8989 - mse: 2.8989\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.9183 - mse: 2.9183\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 2.4048 - mse: 2.4048\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.3368 - mse: 2.3368\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.6788 - mse: 2.6788\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.8876 - mse: 3.8876\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.4930 - mse: 2.4930\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.7689 - mse: 1.7689\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9330 - mse: 1.9330\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1158 - mse: 2.1158\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 5.7123 - mse: 5.7123\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.8072 - mse: 3.8072\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7208 - mse: 1.7208\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.8008 - mse: 1.8008\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7754 - mse: 1.7754\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6606 - mse: 1.6606\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.1132 - mse: 3.1132\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.4549 - mse: 4.4549\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.1119 - mse: 3.1119\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.4791 - mse: 2.4791\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.8865 - mse: 1.8865\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.7124 - mse: 1.7124\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3575 - mse: 2.3575\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.6876 - mse: 4.6876\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.0584 - mse: 4.0584\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.7567 - mse: 3.7567\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.6804 - mse: 3.6804\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7834 - mse: 1.7834\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8403 - mse: 1.8403\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7128 - mse: 1.7128\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.7010 - mse: 3.7010\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.1899 - mse: 3.1899\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.0128 - mse: 2.0128\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1226 - mse: 2.1226\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9538 - mse: 1.9538\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.6226 - mse: 1.6226\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.6358 - mse: 1.6358\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.2447 - mse: 2.2447\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.9940 - mse: 5.9940\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.7042 - mse: 4.7042\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.4372 - mse: 3.4372\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.1928 - mse: 2.1928\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.0563 - mse: 2.0563\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.4435 - mse: 2.4435\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.1373 - mse: 2.1373\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.6706 - mse: 2.6706\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.4210 - mse: 3.4210\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8429 - mse: 1.8429\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6225 - mse: 1.6225\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6816 - mse: 1.6816\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.4927 - mse: 3.4927\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 4.8043 - mse: 4.8043\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7609 - mse: 1.7609\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.5658 - mse: 1.5658\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6212 - mse: 1.6212\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7461 - mse: 1.7461\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.1639 - mse: 2.1639\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.5912 - mse: 1.5912\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5884 - mse: 1.5884\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.4286 - mse: 3.4286\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2981 - mse: 7.2981\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.7793 - mse: 3.7793\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.5918 - mse: 1.5918\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5623 - mse: 1.5623\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5306 - mse: 1.5306\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5994 - mse: 1.5994\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.2291 - mse: 2.2291\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2179 - mse: 3.2179\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.8556 - mse: 4.8556\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.6350 - mse: 4.6350\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8345 - mse: 1.8345\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5199 - mse: 1.5199\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6548 - mse: 1.6548\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9846 - mse: 1.9846\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.1445 - mse: 3.1445\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.7995 - mse: 2.7995\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4445 - mse: 2.4445\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6992 - mse: 1.6992\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.4937 - mse: 1.4937\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.2473 - mse: 2.2473\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.9850 - mse: 5.9850\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.7314 - mse: 3.7314\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2204 - mse: 3.2204\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8807 - mse: 1.8807\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.8511 - mse: 1.8511\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7288 - mse: 1.7288\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7874 - mse: 2.7874\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.6319 - mse: 2.6319\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7061 - mse: 1.7061\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9467 - mse: 1.9467\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.9694 - mse: 3.9694\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.5244 - mse: 4.5244\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.3633 - mse: 4.3633\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0130 - mse: 2.0130\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0690 - mse: 2.0690\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7384 - mse: 2.7384\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4560 - mse: 2.4560\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6090 - mse: 1.6090\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4568 - mse: 1.4568\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3641 - mse: 2.3641\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8966 - mse: 2.8966\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3108 - mse: 3.3108\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5319 - mse: 1.5319\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5666 - mse: 1.5666\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7197 - mse: 2.7197\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.5973 - mse: 6.5973\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.5561 - mse: 4.5561\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6452 - mse: 1.6452\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5128 - mse: 1.5128\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.2137 - mse: 2.2137\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5605 - mse: 1.5605\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0622 - mse: 2.0622\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8308 - mse: 1.8308\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.4609 - mse: 3.4609\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.8971 - mse: 4.8971\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7732 - mse: 1.7732\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4148 - mse: 1.4148\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6000 - mse: 1.6000\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4611 - mse: 1.4611\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3461 - mse: 3.3461\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.2296 - mse: 4.2296\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1783 - mse: 4.1783\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8370 - mse: 1.8370\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.4090 - mse: 1.4090\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.8434 - mse: 1.8434\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.2780 - mse: 4.2780\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.5021 - mse: 2.5021\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4422 - mse: 1.4422\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3981 - mse: 1.3981\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.2243 - mse: 2.2243\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1651 - mse: 4.1651\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.7132 - mse: 3.7132\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4459 - mse: 2.4459\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4757 - mse: 1.4757\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5187 - mse: 1.5187\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.3755 - mse: 1.3755\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9322 - mse: 1.9322\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.1270 - mse: 3.1270\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7890 - mse: 2.7890\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0053 - mse: 3.0053\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.3281 - mse: 4.3281\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4116 - mse: 1.4116\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3936 - mse: 2.3936\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.9477 - mse: 3.9477\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8637 - mse: 1.8637\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4166 - mse: 1.4166\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5195 - mse: 1.5195\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5337 - mse: 1.5337\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3769 - mse: 1.3769\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3969 - mse: 1.3969\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3531 - mse: 1.3531\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8981 - mse: 1.8981\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.6489 - mse: 6.6489\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.9886 - mse: 2.9886\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5456 - mse: 1.5456\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1879 - mse: 2.1879\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7309 - mse: 2.7309\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.6576 - mse: 2.6576\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4617 - mse: 1.4617\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4172 - mse: 1.4172\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8306 - mse: 1.8306\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.1362 - mse: 3.1362\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.8721 - mse: 4.8721\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9326 - mse: 1.9326\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7343 - mse: 1.7343\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9486 - mse: 1.9486\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3535 - mse: 1.3535\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4745 - mse: 1.4745\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9813 - mse: 1.9813\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7191 - mse: 2.7191\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.1658 - mse: 6.1658\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1816 - mse: 2.1816\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6537 - mse: 1.6537\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3237 - mse: 1.3237\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3980 - mse: 1.3980\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.1926 - mse: 2.1926\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9496 - mse: 1.9496\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.5666 - mse: 1.5666\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.3554 - mse: 3.3554\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 5.9617 - mse: 5.9617\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 2.3780 - mse: 2.3780\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.5269 - mse: 1.5269\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9342 - mse: 1.9342\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7299 - mse: 1.7299\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.3725 - mse: 1.3725\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5033 - mse: 1.5033\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4156 - mse: 1.4156\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3262 - mse: 1.3262\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.7709 - mse: 2.7709\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1774 - mse: 7.1774\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1647 - mse: 2.1647\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3647 - mse: 1.3647\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5943 - mse: 1.5943\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4223 - mse: 1.4223\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3550 - mse: 2.3550\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.2982 - mse: 5.2982\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8494 - mse: 2.8494\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.2368 - mse: 2.2368\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9090 - mse: 1.9090\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6048 - mse: 1.6048\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8883 - mse: 1.8883\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3292 - mse: 1.3292\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7077 - mse: 1.7077\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.5460 - mse: 3.5460\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.2080 - mse: 4.2080\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8826 - mse: 1.8826\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4286 - mse: 1.4286\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3374 - mse: 1.3374\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3043 - mse: 1.3043\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.8902 - mse: 1.8902\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1011 - mse: 4.1011\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.6826 - mse: 3.6826\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4117 - mse: 1.4117\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0368 - mse: 2.0368\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.6713 - mse: 2.6713\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5623 - mse: 1.5623\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0178 - mse: 2.0178\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.9674 - mse: 3.9674\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.9518 - mse: 4.9518\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7783 - mse: 1.7783\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2704 - mse: 1.2704\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2628 - mse: 1.2628\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3884 - mse: 1.3884\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3993 - mse: 1.3993\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2619 - mse: 1.2619\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2499 - mse: 1.2499\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.1539 - mse: 2.1539\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.9532 - mse: 6.9532\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9792 - mse: 1.9792\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4599 - mse: 1.4599\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2567 - mse: 1.2567\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5903 - mse: 1.5903\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7509 - mse: 2.7509\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0261 - mse: 3.0261\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2758 - mse: 3.2758\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8475 - mse: 1.8475\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5766 - mse: 1.5766\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2388 - mse: 1.2388\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2440 - mse: 1.2440\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3971 - mse: 1.3971\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9806 - mse: 1.9806\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.9593 - mse: 3.9593\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7768 - mse: 1.7768\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2285 - mse: 1.2285\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.3405 - mse: 1.3405\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6226 - mse: 1.6226\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.5353 - mse: 3.5353\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.0177 - mse: 6.0177\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.5364 - mse: 3.5364\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5411 - mse: 1.5411\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2411 - mse: 1.2411\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.3245 - mse: 1.3245\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.3920 - mse: 1.3920\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.2703 - mse: 1.2703\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.3854 - mse: 1.3854\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4939 - mse: 2.4939\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.8412 - mse: 5.8412\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.1704 - mse: 3.1704\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.8856 - mse: 1.8856\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8538 - mse: 1.8538\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6215 - mse: 1.6215\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5333 - mse: 1.5333\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6454 - mse: 1.6454\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.8529 - mse: 3.8529\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.7624 - mse: 3.7624\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.8228 - mse: 1.8228\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2516 - mse: 2.2516\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 2.5386 - mse: 2.5386\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3398 - mse: 1.3398\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7178 - mse: 1.7178\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.7789 - mse: 2.7789\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8659 - mse: 2.8659\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3004 - mse: 2.3004\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6493 - mse: 1.6493\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2227 - mse: 1.2227\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.9084 - mse: 1.9084\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.7198 - mse: 4.7198\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6154 - mse: 1.6154\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8426 - mse: 1.8426\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.5297 - mse: 2.5297\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1369 - mse: 2.1369\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.1929 - mse: 3.1929\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.1921 - mse: 3.1921\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.5688 - mse: 1.5688\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2063 - mse: 1.2063\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3311 - mse: 1.3311\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9151 - mse: 1.9151\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3623 - mse: 3.3623\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1801 - mse: 2.1801\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.1942 - mse: 1.1942\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7327 - mse: 1.7327\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2491 - mse: 2.2491\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0629 - mse: 3.0629\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2192 - mse: 3.2192\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0273 - mse: 2.0273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1598ea700>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.10976417, -0.11118057,  0.10978648],\n",
       "        [ 0.23281783, -0.23475456,  0.23286201],\n",
       "        [ 0.16636847, -0.16802043,  0.16640036],\n",
       "        [ 0.25329313, -0.25511673,  0.2533335 ],\n",
       "        [-0.00053986,  0.00288974, -0.00065306],\n",
       "        [ 0.00953689, -0.00785372,  0.00944587]], dtype=float32),\n",
       " array([ 0.10179962, -0.10132063,  0.10175249], dtype=float32),\n",
       " array([[ 0.9725532 ],\n",
       "        [-0.14655806],\n",
       "        [ 0.7630058 ]], dtype=float32),\n",
       " array([0.10198415], dtype=float32)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 18:48:45.338026: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>18.536709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>17.871172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>17.982235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>21.744883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>12.802050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8   18.536709\n",
       "AK       18.1   17.871172\n",
       "AZ       18.6   17.982235\n",
       "AR       22.4   21.744883\n",
       "CA       12.0   12.802050"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2447601343428383"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to `kernel_initializer` the weights to 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='ones'))\n",
    "model.add(layer=Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a Prediction with the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Can we make a prediction for for `Washington DC` accidents\n",
    "> - With the already initialized Mathematical Equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')\n",
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                \n",
       "AL         7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 18:49:23.308396: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[138.81078]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(AL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[ 0.04539084],\n",
       "        [-0.9930145 ],\n",
       "        [ 1.089893  ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>138.810776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>175.369736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>150.096710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>145.388153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>152.683411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8  138.810776\n",
       "AK       18.1  175.369736\n",
       "AZ       18.6  150.096710\n",
       "AR       22.4  145.388153\n",
       "CA       12.0  152.683411"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18975.672927183088"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fit()` the `model` and compare again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17194.9180 - mse: 17194.9180\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10998.2285 - mse: 10998.2285\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7899.6123 - mse: 7899.6123\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5772.9756 - mse: 5772.9756\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4201.3472 - mse: 4201.3472\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3044.2864 - mse: 3044.2864\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2186.9197 - mse: 2186.9197\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1534.6572 - mse: 1534.6572\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1059.9769 - mse: 1059.9769\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 716.4389 - mse: 716.4389\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 468.6841 - mse: 468.6841\n",
      "Epoch 12/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 297.4897 - mse: 297.4897"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 18:49:55.028314: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 295.3433 - mse: 295.3433\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 181.1785 - mse: 181.1785\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 111.0138 - mse: 111.0138\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 71.1494 - mse: 71.1494\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 48.0297 - mse: 48.0297\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 35.8477 - mse: 35.8477\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.4103 - mse: 30.4103\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.4600 - mse: 28.4600\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 28.2400 - mse: 28.2400\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.5942 - mse: 27.5942\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.2985 - mse: 27.2985\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.2281 - mse: 27.2281\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.1524 - mse: 27.1524\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 27.1940 - mse: 27.1940\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.3928 - mse: 27.3928\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.4688 - mse: 27.4688\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.6941 - mse: 27.6941\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 27.0951 - mse: 27.0951\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.2445 - mse: 27.2445\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.9607 - mse: 26.9607\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 26.0742 - mse: 26.0742\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.7284 - mse: 26.7284\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.9313 - mse: 26.9313\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 25.5554 - mse: 25.5554\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 33.3589 - mse: 33.3589\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 34.4680 - mse: 34.4680\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.8564 - mse: 26.8564\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.6611 - mse: 27.6611\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.9559 - mse: 28.9559\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.9224 - mse: 23.9224\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.9148 - mse: 26.9148\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.7388 - mse: 28.7388\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 32.5894 - mse: 32.5894\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 38.8184 - mse: 38.8184\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.9624 - mse: 26.9624\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.2112 - mse: 22.2112\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 33.1017 - mse: 33.1017\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 37.1945 - mse: 37.1945\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.9206 - mse: 24.9206\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.1125 - mse: 27.1125\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 32.0426 - mse: 32.0426\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 52.5856 - mse: 52.5856\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 34.5700 - mse: 34.5700\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.4816 - mse: 24.4816\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 19.9070 - mse: 19.9070\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.2089 - mse: 21.2089\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.8108 - mse: 25.8108\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.2974 - mse: 19.2974\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.5026 - mse: 26.5026\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 34.3856 - mse: 34.3856\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.9885 - mse: 25.9885\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 35.0245 - mse: 35.0245\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 29.8692 - mse: 29.8692\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.9644 - mse: 18.9644\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.1756 - mse: 18.1756\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.2272 - mse: 22.2272\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 30.6969 - mse: 30.6969\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 26.8575 - mse: 26.8575\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 19.7964 - mse: 19.7964\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.7940 - mse: 16.7940\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 49.9807 - mse: 49.9807\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 27.9693 - mse: 27.9693\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.0226 - mse: 16.0226\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.2441 - mse: 16.2441\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.4239 - mse: 16.4239\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 20.5491 - mse: 20.5491\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.1211 - mse: 15.1211\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 31.0367 - mse: 31.0367\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.6594 - mse: 23.6594\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 26.0680 - mse: 26.0680\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.7918 - mse: 16.7918\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.7023 - mse: 23.7023\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 40.9617 - mse: 40.9617\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.6277 - mse: 29.6277\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 23.4581 - mse: 23.4581\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 15.3556 - mse: 15.3556\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 14.3253 - mse: 14.3253\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.3469 - mse: 14.3469\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.4661 - mse: 25.4661\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 20.5596 - mse: 20.5596\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.7411 - mse: 18.7411\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 20.8717 - mse: 20.8717\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 33.8568 - mse: 33.8568\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 14.7624 - mse: 14.7624\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 14.8314 - mse: 14.8314\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.4270 - mse: 13.4270\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.1827 - mse: 25.1827\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 33.7483 - mse: 33.7483\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.7514 - mse: 18.7514\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 17.1515 - mse: 17.1515\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.8003 - mse: 11.8003\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.7064 - mse: 12.7064\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.5480 - mse: 23.5480\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 27.5522 - mse: 27.5522\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 19.5598 - mse: 19.5598\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 31.6913 - mse: 31.6913\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.0353 - mse: 24.0353\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.4284 - mse: 18.4284\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.1462 - mse: 13.1462\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.1683 - mse: 12.1683\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.8115 - mse: 12.8115\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.4644 - mse: 10.4644\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.6847 - mse: 11.6847\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 48.2715 - mse: 48.2715\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 28.5102 - mse: 28.5102\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.0704 - mse: 16.0704\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0541 - mse: 10.0541\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0619 - mse: 11.0619\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0590 - mse: 10.0590\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.4318 - mse: 14.4318\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.5737 - mse: 9.5737\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.8408 - mse: 14.8408\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 33.8651 - mse: 33.8651\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.7220 - mse: 11.7220\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7641 - mse: 8.7641\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.8230 - mse: 9.8230\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.6908 - mse: 11.6908\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7987 - mse: 9.7987\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.8918 - mse: 11.8918\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.8736 - mse: 21.8736\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 30.4389 - mse: 30.4389\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.1397 - mse: 26.1397\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.1157 - mse: 13.1157\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.8642 - mse: 8.8642\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7733 - mse: 8.7733\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.7987 - mse: 7.7987\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9566 - mse: 7.9566\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 9.4907 - mse: 9.4907\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 34.8820 - mse: 34.8820\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 38.5622 - mse: 38.5622\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 7.8274 - mse: 7.8274\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.3230 - mse: 7.3230\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.2971 - mse: 7.2971\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.9393 - mse: 7.9393\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2015 - mse: 11.2015\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 28.5106 - mse: 28.5106\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.9398 - mse: 21.9398\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.5983 - mse: 12.5983\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.5226 - mse: 8.5226\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.2263 - mse: 10.2263\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 15.0839 - mse: 15.0839\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 30.6584 - mse: 30.6584\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.5146 - mse: 16.5146\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.6224 - mse: 6.6224\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.3513 - mse: 6.3513\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 8.0539 - mse: 8.0539\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.8721 - mse: 21.8721\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 34.5152 - mse: 34.5152\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.6343 - mse: 14.6343\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3012 - mse: 8.3012\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.9732 - mse: 5.9732\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.8817 - mse: 5.8817\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.0528 - mse: 6.0528\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9606 - mse: 7.9606\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.2894 - mse: 21.2894\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 40.8236 - mse: 40.8236\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.3142 - mse: 7.3142\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.0937 - mse: 6.0937\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4371 - mse: 11.4371\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.3927 - mse: 7.3927\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.5665 - mse: 5.5665\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.9889 - mse: 5.9889\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 22.9815 - mse: 22.9815\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 42.3575 - mse: 42.3575\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.9174 - mse: 6.9174\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.2864 - mse: 5.2864\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.2992 - mse: 6.2992\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.6346 - mse: 6.6346\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.2129 - mse: 5.2129\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.8529 - mse: 4.8529\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.2957 - mse: 5.2957\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.4706 - mse: 5.4706\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.1134 - mse: 30.1134\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 50.1499 - mse: 50.1499\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 5.8812 - mse: 5.8812\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.3763 - mse: 5.3763\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.4558 - mse: 5.4558\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.1449 - mse: 6.1449\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 10.9729 - mse: 10.9729\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 24.3776 - mse: 24.3776\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 18.5675 - mse: 18.5675\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 12.4354 - mse: 12.4354\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 6.2026 - mse: 6.2026\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.9163 - mse: 5.9163\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 8.8838 - mse: 8.8838\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 22.0630 - mse: 22.0630\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.2517 - mse: 7.2517\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.1534 - mse: 5.1534\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.1451 - mse: 5.1451\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3594 - mse: 8.3594\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 20.0470 - mse: 20.0470\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 20.4346 - mse: 20.4346\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 8.2626 - mse: 8.2626\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.9443 - mse: 8.9443\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 12.9886 - mse: 12.9886\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 17.4846 - mse: 17.4846\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.9933 - mse: 7.9933\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.3171 - mse: 4.3171\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.8653 - mse: 6.8653\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.6979 - mse: 19.6979\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.7407 - mse: 18.7407\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.3981 - mse: 14.3981\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.6555 - mse: 3.6555\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.8630 - mse: 8.8630\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.9710 - mse: 19.9710\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.2371 - mse: 19.2371\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.8812 - mse: 5.8812\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.5245 - mse: 3.5245\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.9004 - mse: 3.9004\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.6708 - mse: 13.6708\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 32.6869 - mse: 32.6869\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.6791 - mse: 11.6791\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.5965 - mse: 4.5965\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.4216 - mse: 4.4216\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 4.8980 - mse: 4.8980\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.3437 - mse: 4.3437\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.3142 - mse: 4.3142\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.7055 - mse: 15.7055\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 31.9601 - mse: 31.9601\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.7711 - mse: 11.7711\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.9227 - mse: 4.9227\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.0951 - mse: 7.0951\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.0920 - mse: 12.0920\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.8721 - mse: 8.8721\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4567 - mse: 8.4567\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.3281 - mse: 5.3281\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 4.4482 - mse: 4.4482\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5259 - mse: 8.5259\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.2018 - mse: 23.2018\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.5547 - mse: 18.5547\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2160 - mse: 10.2160\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.3046 - mse: 7.3046\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9312 - mse: 10.9312\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 12.3039 - mse: 12.3039\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 14.4833 - mse: 14.4833\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.4694 - mse: 11.4694\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.9631 - mse: 3.9631\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.9949 - mse: 5.9949\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.8600 - mse: 13.8600\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.7757 - mse: 7.7757\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.8918 - mse: 3.8918\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.3246 - mse: 8.3246\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 31.0614 - mse: 31.0614\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.9692 - mse: 15.9692\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.5677 - mse: 5.5677\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.7818 - mse: 2.7818\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.4710 - mse: 3.4710\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.0132 - mse: 5.0132\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.2153 - mse: 8.2153\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.4339 - mse: 13.4339\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.1015 - mse: 25.1015\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.7335 - mse: 17.7335\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.3866 - mse: 10.3866\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.4360 - mse: 8.4360\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.8414 - mse: 4.8414\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 6.9845 - mse: 6.9845\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.2131 - mse: 11.2131\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 15.3374 - mse: 15.3374\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 9.7869 - mse: 9.7869\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.3451 - mse: 10.3451\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.1495 - mse: 11.1495\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.1113 - mse: 11.1113\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.7358 - mse: 5.7358\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.6560 - mse: 3.6560\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.7304 - mse: 5.7304\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.3651 - mse: 7.3651\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.6635 - mse: 14.6635\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.4243 - mse: 21.4243\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.0174 - mse: 12.0174\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7169 - mse: 8.7169\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5210 - mse: 8.5210\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0333 - mse: 10.0333\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7405 - mse: 9.7405\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.0571 - mse: 9.0571\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4359 - mse: 11.4359\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.2969 - mse: 13.2969\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.5689 - mse: 9.5689\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.0646 - mse: 9.0646\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.9999 - mse: 13.9999\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.5386 - mse: 12.5386\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1935 - mse: 10.1935\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.3341 - mse: 6.3341\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0080 - mse: 3.0080\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8388 - mse: 2.8388\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.3734 - mse: 4.3734\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.9290 - mse: 20.9290\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 28.5069 - mse: 28.5069\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.1437 - mse: 12.1437\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.5126 - mse: 3.5126\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 2.9993 - mse: 2.9993\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.6100 - mse: 4.6100\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.3735 - mse: 11.3735\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.1049 - mse: 18.1049\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.2399 - mse: 13.2399\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 6.7319 - mse: 6.7319\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.0117 - mse: 8.0117\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 8.7539 - mse: 8.7539\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 13.3931 - mse: 13.3931\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.0082 - mse: 12.0082\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.8392 - mse: 7.8392\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 4.7468 - mse: 4.7468\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.5823 - mse: 2.5823\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.1523 - mse: 2.1523\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.3750 - mse: 2.3750\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.0846 - mse: 13.0846\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 40.0240 - mse: 40.0240\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 18.3214 - mse: 18.3214\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.1430 - mse: 6.1430\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.4879 - mse: 2.4879\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.9058 - mse: 3.9058\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.4475 - mse: 3.4475\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.4190 - mse: 2.4190\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.1781 - mse: 3.1781\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 14.5392 - mse: 14.5392\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.2653 - mse: 22.2653\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.7871 - mse: 18.7871\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.8322 - mse: 11.8322\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 6.5983 - mse: 6.5983\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.4860 - mse: 2.4860\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.2334 - mse: 3.2334\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.9367 - mse: 7.9367\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.2401 - mse: 14.2401\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.3264 - mse: 14.3264\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.5639 - mse: 11.5639\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.8461 - mse: 9.8461\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2601 - mse: 7.2601\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.3232 - mse: 10.3232\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.1913 - mse: 7.1913\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.6140 - mse: 8.6140\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 4.4957 - mse: 4.4957\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.6750 - mse: 5.6750\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 19.7671 - mse: 19.7671\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 14.6162 - mse: 14.6162\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 4.3552 - mse: 4.3552\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.1306 - mse: 7.1306\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 13.7326 - mse: 13.7326\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 7.1945 - mse: 7.1945\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.0693 - mse: 4.0693\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1929 - mse: 4.1929\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2011 - mse: 7.2011\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 10.0270 - mse: 10.0270\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.8038 - mse: 16.8038\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.3054 - mse: 14.3054\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.6716 - mse: 12.6716\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.0871 - mse: 6.0871\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 5.1853 - mse: 5.185 - 0s 7ms/step - loss: 4.7353 - mse: 4.7353\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.9622 - mse: 3.9622\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2385 - mse: 2.2385\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.1338 - mse: 2.1338\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.8099 - mse: 5.8099\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.4657 - mse: 25.4657\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.5028 - mse: 23.5028\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1954 - mse: 4.1954\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.8251 - mse: 2.8251\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.4360 - mse: 2.4360\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.2948 - mse: 4.2948\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.0864 - mse: 6.0864\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.4729 - mse: 13.4729\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.8570 - mse: 20.8570\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.2332 - mse: 14.2332\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.8000 - mse: 6.8000\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.8527 - mse: 3.8527\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1628 - mse: 2.1628\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.0296 - mse: 4.0296\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4241 - mse: 11.4241\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.6577 - mse: 18.6577\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.4239 - mse: 11.4239\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.8585 - mse: 5.8585\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.4702 - mse: 6.4702\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6698 - mse: 8.6698\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.4808 - mse: 5.4808\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 5.9007 - mse: 5.9007\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.5317 - mse: 9.5317\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.3709 - mse: 18.3709\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.9078 - mse: 15.9078\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.0130 - mse: 9.0130\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.1956 - mse: 8.1956\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 6.1627 - mse: 6.1627\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.1710 - mse: 10.1710\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.2967 - mse: 13.2967\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.3513 - mse: 8.3513\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 5.8041 - mse: 5.8041\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 5.2513 - mse: 5.2513\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.9776 - mse: 5.9776\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.0522 - mse: 9.0522\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.6641 - mse: 16.6641\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.8904 - mse: 12.8904\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.1917 - mse: 4.1917\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8301 - mse: 2.8301\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.2170 - mse: 3.2170\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.9815 - mse: 3.9815\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 9.0565 - mse: 9.0565\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.1853 - mse: 24.1853\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.5560 - mse: 19.5560\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9222 - mse: 7.9222\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.3782 - mse: 5.3782\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0165 - mse: 7.0165\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.7093 - mse: 7.7093\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7099 - mse: 9.7099\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9086 - mse: 10.9086\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4356 - mse: 8.4356\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.5270 - mse: 4.5270\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.2638 - mse: 7.2638\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.4933 - mse: 16.4933\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1488 - mse: 11.1488\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.3909 - mse: 5.3909\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.2810 - mse: 4.2810\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.8740 - mse: 5.8740\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3951 - mse: 11.3951\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.0904 - mse: 21.0904\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.7209 - mse: 11.7209\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.6396 - mse: 3.6396\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.2637 - mse: 3.2637\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.7313 - mse: 3.7313\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.6393 - mse: 8.6393\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.2441 - mse: 15.2441\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.5202 - mse: 11.5202\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.9055 - mse: 4.9055\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.1969 - mse: 4.1969\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.8647 - mse: 7.8647\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.3221 - mse: 6.3221\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.0645 - mse: 4.0645\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 6.4217 - mse: 6.4217\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 11.9312 - mse: 11.9312\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.1483 - mse: 10.1483\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 13.6175 - mse: 13.6175\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.1234 - mse: 13.1234\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 13.7818 - mse: 13.7818\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.4022 - mse: 8.4022\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.3199 - mse: 3.3199\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 2.8725 - mse: 2.8725\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0197 - mse: 2.0197\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.8786 - mse: 1.8786\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.1097 - mse: 2.1097\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.1006 - mse: 7.1006\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 41.1612 - mse: 41.1612\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 12.7972 - mse: 12.7972\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 6.1857 - mse: 6.1857\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 3.0179 - mse: 3.0179\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.0188 - mse: 4.0188\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 6.5005 - mse: 6.5005\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 11.5306 - mse: 11.5306\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.9797 - mse: 13.9797\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.5709 - mse: 11.5709\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6754 - mse: 7.6754\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.7529 - mse: 6.7529\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.2003 - mse: 4.2003\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.2195 - mse: 4.2195\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.3459 - mse: 5.3459\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.7037 - mse: 9.7037\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.8323 - mse: 16.8323\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.5444 - mse: 12.5444\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.9459 - mse: 5.9459\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.9491 - mse: 3.9491\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.1272 - mse: 3.1272\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.9469 - mse: 4.9469\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.0121 - mse: 15.0121\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.9429 - mse: 23.9429\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.1316 - mse: 11.1316\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.5108 - mse: 3.5108\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.0030 - mse: 2.0030\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3083 - mse: 2.3083\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.5636 - mse: 3.5636\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.1933 - mse: 11.1933\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.5517 - mse: 26.5517\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6306 - mse: 10.6306\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.5011 - mse: 3.5011\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.6546 - mse: 3.6546\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.8809 - mse: 6.8809\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.9540 - mse: 9.9540\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.9097 - mse: 11.9097\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.3162 - mse: 11.3162\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.9022 - mse: 11.9022\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6651 - mse: 7.6651\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8024 - mse: 2.8024\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0968 - mse: 2.0968\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6808 - mse: 1.6808\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7498 - mse: 1.7498\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.2801 - mse: 11.2801\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 35.8352 - mse: 35.8352\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5950 - mse: 8.5950\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4557 - mse: 2.4557\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6743 - mse: 1.6743\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1515 - mse: 2.1515\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.4902 - mse: 4.4902\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7796 - mse: 8.7796\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.2835 - mse: 22.2835\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.4586 - mse: 14.4586\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.0711 - mse: 6.0711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15bdcdfd0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.0803863 , 0.900651  , 1.0986634 ],\n",
       "        [1.1429759 , 0.83845484, 1.1608735 ],\n",
       "        [1.112536  , 0.8686107 , 1.1307063 ],\n",
       "        [1.1362538 , 0.8452662 , 1.1540655 ],\n",
       "        [0.95242155, 1.0328588 , 0.96668226],\n",
       "        [0.96591276, 1.0182456 , 0.9812393 ]], dtype=float32),\n",
       " array([ 0.02067563, -0.03774948,  0.03717197], dtype=float32),\n",
       " array([[ 0.0204669],\n",
       "        [-1.0184165],\n",
       "        [ 1.0650133]], dtype=float32),\n",
       " array([0.03745592], dtype=float32)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 18:50:31.531885: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>18.280220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>16.944523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>16.857445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>20.723339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>12.649424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8   18.280220\n",
       "AK       18.1   16.944523\n",
       "AZ       18.6   16.857445\n",
       "AR       22.4   20.723339\n",
       "CA       12.0   12.649424"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4798831092193554"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to `kernel_initializer` the weights to `glorot_uniform` (default)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a Prediction with the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Can we make a prediction for for `Washington DC` accidents\n",
    "> - With the already initialized Mathematical Equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')\n",
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                \n",
       "AL         7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x15c8f5670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 18:53:43.200876: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[99.78448]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(AL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.6064944 , -0.05474722,  0.46676135],\n",
       "        [ 0.03026056, -0.66200966,  0.7265953 ],\n",
       "        [ 0.3309511 ,  0.48746276, -0.1870107 ],\n",
       "        [-0.6015929 ,  0.79233575, -0.248079  ],\n",
       "        [-0.14898151,  0.59505224,  0.632252  ],\n",
       "        [-0.40874237, -0.42809725, -0.4343371 ]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[ 0.4964267 ],\n",
       "        [ 0.73119414],\n",
       "        [-0.28051603]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>99.784477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>154.049133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>134.372482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>112.065483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>104.449394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8   99.784477\n",
       "AK       18.1  154.049133\n",
       "AZ       18.6  134.372482\n",
       "AR       22.4  112.065483\n",
       "CA       12.0  104.449394"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11651.052261500548"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fit()` the `model` and compare again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11019.3604 - mse: 11019.3604\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8397.8555 - mse: 8397.8555\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6842.3765 - mse: 6842.3765\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5687.1836 - mse: 5687.1836\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4768.8530 - mse: 4768.8530\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3987.5247 - mse: 3987.5247\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3328.8452 - mse: 3328.8452\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2790.1975 - mse: 2790.1975\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2333.0967 - mse: 2333.0967\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1927.9374 - mse: 1927.9374\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1577.1807 - mse: 1577.1807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 18:54:06.357399: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1283.0073 - mse: 1283.0073\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1038.4386 - mse: 1038.4386\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 827.8225 - mse: 827.8225\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 655.7411 - mse: 655.7411\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 518.8636 - mse: 518.8636\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 409.0315 - mse: 409.0315\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 327.1448 - mse: 327.1448\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 264.4889 - mse: 264.4889\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 218.5727 - mse: 218.5727\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 187.2056 - mse: 187.2056\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 165.5181 - mse: 165.5181\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 149.7897 - mse: 149.7897\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 139.2242 - mse: 139.2242\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 133.4695 - mse: 133.4695\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 130.5396 - mse: 130.5396\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 129.3627 - mse: 129.3627\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 128.5547 - mse: 128.5547\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 128.5036 - mse: 128.5036\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 127.5984 - mse: 127.5984\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 128.5592 - mse: 128.5592\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 128.1906 - mse: 128.1906\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 126.2007 - mse: 126.2007\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 125.4088 - mse: 125.4088\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 126.1662 - mse: 126.1662\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 128.3697 - mse: 128.3697\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 126.6232 - mse: 126.6232\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 128.3205 - mse: 128.3205\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 124.0650 - mse: 124.0650\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 122.0461 - mse: 122.0461\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 121.9900 - mse: 121.9900\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 120.3082 - mse: 120.3082\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 118.6197 - mse: 118.6197\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 117.4199 - mse: 117.4199\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 118.4606 - mse: 118.4606\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 122.7273 - mse: 122.7273\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 119.5683 - mse: 119.5683\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 114.2953 - mse: 114.2953\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 118.2261 - mse: 118.2261\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 112.5667 - mse: 112.5667\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 112.3719 - mse: 112.3719\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 110.7343 - mse: 110.7343\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 107.8653 - mse: 107.8653\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 118.4258 - mse: 118.4258\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 113.8050 - mse: 113.8050\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 110.2746 - mse: 110.2746\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 106.7505 - mse: 106.7505\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 116.8935 - mse: 116.8935\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 105.9302 - mse: 105.9302\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 102.7318 - mse: 102.7318\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 101.7709 - mse: 101.7709\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 101.0065 - mse: 101.0065\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 104.5310 - mse: 104.5310\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 101.5771 - mse: 101.5771\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 97.4742 - mse: 97.4742\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 106.8440 - mse: 106.8440\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 99.3477 - mse: 99.3477\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 99.4480 - mse: 99.4480\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 104.0527 - mse: 104.0527\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 96.0377 - mse: 96.0377\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 96.3753 - mse: 96.3753\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 92.4078 - mse: 92.4078\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 92.2670 - mse: 92.2670\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 91.4398 - mse: 91.4398\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 91.2847 - mse: 91.2847\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 88.6149 - mse: 88.6149\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 95.6820 - mse: 95.6820\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 89.7059 - mse: 89.7059\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 88.8184 - mse: 88.8184\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 93.0182 - mse: 93.0182\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 85.1761 - mse: 85.1761\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 82.4189 - mse: 82.4189\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 82.3168 - mse: 82.3168\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 81.2771 - mse: 81.2771\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 81.8995 - mse: 81.8995\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 85.1900 - mse: 85.1900\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 82.3150 - mse: 82.3150\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 85.6251 - mse: 85.6251\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 82.6065 - mse: 82.6065\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 80.4471 - mse: 80.4471\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 76.8349 - mse: 76.8349\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 75.6635 - mse: 75.6635\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 77.7273 - mse: 77.7273\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 76.6456 - mse: 76.6456\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 77.4817 - mse: 77.4817\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 73.4636 - mse: 73.4636\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 79.8915 - mse: 79.8915\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 75.3414 - mse: 75.3414\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 70.0610 - mse: 70.0610\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 68.1537 - mse: 68.1537\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 72.4548 - mse: 72.4548\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 71.9980 - mse: 71.9980\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 77.3315 - mse: 77.3315\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 69.2066 - mse: 69.2066\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 69.4894 - mse: 69.4894\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 65.6468 - mse: 65.6468\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 67.4481 - mse: 67.4481\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 65.8719 - mse: 65.8719\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 74.7427 - mse: 74.7427\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 70.7491 - mse: 70.7491\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 70.3031 - mse: 70.3031\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 65.0124 - mse: 65.0124\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 64.7427 - mse: 64.7427\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 61.5259 - mse: 61.5259\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 65.1437 - mse: 65.1437\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 63.0524 - mse: 63.0524\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 60.5040 - mse: 60.5040\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 57.7321 - mse: 57.7321\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 59.8280 - mse: 59.8280\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 61.1511 - mse: 61.1511\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 58.2275 - mse: 58.2275\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 71.0542 - mse: 71.0542\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 57.0757 - mse: 57.0757\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 55.4123 - mse: 55.4123\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 54.8013 - mse: 54.8013\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 55.5499 - mse: 55.5499\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 61.2177 - mse: 61.2177\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 56.0211 - mse: 56.0211\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 52.7786 - mse: 52.7786\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 54.4810 - mse: 54.4810\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 53.5315 - mse: 53.5315\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 55.9447 - mse: 55.9447\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 60.2258 - mse: 60.2258\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 56.4112 - mse: 56.4112\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 49.2563 - mse: 49.2563\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 48.7363 - mse: 48.7363\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 48.9306 - mse: 48.9306\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 48.8872 - mse: 48.8872\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 53.0448 - mse: 53.0448\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 46.6693 - mse: 46.6693\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 46.9849 - mse: 46.9849\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 50.7987 - mse: 50.7987\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 45.0047 - mse: 45.0047\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 48.8123 - mse: 48.8123\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 65.1588 - mse: 65.1588\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 48.5543 - mse: 48.5543\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 46.2655 - mse: 46.2655\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 46.8711 - mse: 46.8711\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 48.9031 - mse: 48.9031\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 54.6794 - mse: 54.6794\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 44.5413 - mse: 44.5413\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 41.9561 - mse: 41.9561\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 41.2103 - mse: 41.2103\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 41.7894 - mse: 41.7894\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 41.0465 - mse: 41.0465\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 41.6151 - mse: 41.6151\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 39.9568 - mse: 39.9568\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 39.3604 - mse: 39.3604\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 39.7586 - mse: 39.7586\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 38.2003 - mse: 38.2003\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 49.7732 - mse: 49.7732\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 41.8628 - mse: 41.8628\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 36.9889 - mse: 36.9889\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 36.0815 - mse: 36.0815\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 35.8724 - mse: 35.8724\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 36.1161 - mse: 36.1161\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 34.9057 - mse: 34.9057\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 37.3710 - mse: 37.3710\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 36.2168 - mse: 36.2168\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 36.1143 - mse: 36.1143\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 41.0574 - mse: 41.0574\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 42.3189 - mse: 42.3189\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 32.3184 - mse: 32.3184\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 31.7486 - mse: 31.7486\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 31.3398 - mse: 31.3398\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 35.7064 - mse: 35.7064\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 32.3046 - mse: 32.3046\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 30.4417 - mse: 30.4417\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 32.1136 - mse: 32.1136\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 42.8987 - mse: 42.8987\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 30.9421 - mse: 30.9421\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 32.3940 - mse: 32.3940\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 28.5618 - mse: 28.5618\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 28.4830 - mse: 28.4830\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 28.1767 - mse: 28.1767\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 32.0486 - mse: 32.0486\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 27.3789 - mse: 27.3789\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 27.1600 - mse: 27.1600\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 31.9117 - mse: 31.9117\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 27.6929 - mse: 27.6929\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 29.8738 - mse: 29.8738\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.7688 - mse: 27.7688\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.1359 - mse: 26.1359\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.4295 - mse: 25.4295\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 27.2970 - mse: 27.2970\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 41.9524 - mse: 41.9524\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.6727 - mse: 30.6727\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.5257 - mse: 25.5257\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.8344 - mse: 23.8344\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 23.7804 - mse: 23.7804\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.0124 - mse: 24.0124\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.2738 - mse: 23.2738\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 28.6329 - mse: 28.6329\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.4791 - mse: 25.4791\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.9036 - mse: 30.9036\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 26.9694 - mse: 26.9694\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 21.7811 - mse: 21.7811\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.3736 - mse: 21.3736\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.9693 - mse: 22.9693\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.3844 - mse: 24.3844\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.8765 - mse: 22.8765\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.8309 - mse: 21.8309\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.7553 - mse: 20.7553\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.7901 - mse: 22.7901\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.0090 - mse: 26.0090\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 23.8686 - mse: 23.8686\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.4318 - mse: 22.4318\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.6064 - mse: 19.6064\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.9969 - mse: 23.9969\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.8779 - mse: 18.8779\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.3310 - mse: 20.3310\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.5426 - mse: 18.5426\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.8429 - mse: 19.8429\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.7574 - mse: 17.7574\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.1878 - mse: 20.1878\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.4145 - mse: 22.4145\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.0888 - mse: 17.0888\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.8780 - mse: 16.8780\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.5353 - mse: 21.5353\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.1791 - mse: 27.1791\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.4238 - mse: 16.4238\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.3797 - mse: 19.3797\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.1903 - mse: 17.1903\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.9004 - mse: 15.9004\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.8295 - mse: 15.8295\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.4229 - mse: 15.4229\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.1718 - mse: 17.1718\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.1946 - mse: 16.1946\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.7112 - mse: 28.7112\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.9480 - mse: 18.9480\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.7631 - mse: 15.7631\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.4662 - mse: 14.4662\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.6749 - mse: 14.6749\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.5895 - mse: 15.5895\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.1339 - mse: 17.1339\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.4057 - mse: 14.4057\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.7344 - mse: 15.7344\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.9866 - mse: 18.9866\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.0603 - mse: 16.0603\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.2186 - mse: 16.2186\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.7210 - mse: 14.7210\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.9596 - mse: 16.9596\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.1374 - mse: 18.1374\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.7390 - mse: 17.7390\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.5808 - mse: 19.5808\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9049 - mse: 12.9049\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.4420 - mse: 12.4420\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.6323 - mse: 13.6323\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.3414 - mse: 12.3414\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.8635 - mse: 13.8635\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.4798 - mse: 13.4798\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.8851 - mse: 11.8851\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.2789 - mse: 15.2789\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.0345 - mse: 12.0345\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.1940 - mse: 12.1940\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.5594 - mse: 14.5594\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.7425 - mse: 18.7425\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1486 - mse: 11.1486\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.3791 - mse: 11.3791\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.9979 - mse: 10.9979\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.0095 - mse: 11.0095\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.5374 - mse: 15.5374\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 20.0302 - mse: 20.0302\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 11.1478 - mse: 11.1478\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.5935 - mse: 10.5935\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.4372 - mse: 12.4372\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.7749 - mse: 11.7749\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.2637 - mse: 11.2637\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.3003 - mse: 21.3003\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.1098 - mse: 18.1098\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.0579 - mse: 12.0579\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0964 - mse: 10.0964\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7859 - mse: 9.7859\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.1384 - mse: 12.1384\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.3744 - mse: 14.3744\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 10.3437 - mse: 10.3437\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.5465 - mse: 9.5465\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.9278 - mse: 10.9278\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.2331 - mse: 16.2331\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9490 - mse: 12.9490\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0969 - mse: 11.0969\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8994 - mse: 8.8994\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8297 - mse: 8.8297\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.3762 - mse: 9.3762\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.2925 - mse: 14.2925\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.1556 - mse: 13.1556\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8058 - mse: 8.8058\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4908 - mse: 9.4908\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.2856 - mse: 10.2856\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.7096 - mse: 11.7096\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.7978 - mse: 15.7978\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.1916 - mse: 12.1916\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5447 - mse: 8.5447\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.9895 - mse: 7.9895\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.2140 - mse: 8.2140\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.9910 - mse: 8.9910\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.6749 - mse: 14.6749\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.8537 - mse: 7.8537\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6495 - mse: 7.6495\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1398 - mse: 11.1398\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.0971 - mse: 10.0971\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.5036 - mse: 7.5036\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.8153 - mse: 11.8153\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.2639 - mse: 14.2639\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.7685 - mse: 10.7685\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.4812 - mse: 7.4812\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1928 - mse: 7.1928\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.2723 - mse: 8.2723\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8658 - mse: 8.8658\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.6021 - mse: 8.6021\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.8166 - mse: 11.8166\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.8982 - mse: 8.8982\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.6429 - mse: 8.6429\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.3543 - mse: 11.3543\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.9482 - mse: 6.9482\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4734 - mse: 11.4734\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.3029 - mse: 11.3029\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.1027 - mse: 7.1027\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.5809 - mse: 6.5809\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2112 - mse: 7.2112\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.3599 - mse: 10.3599\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.0640 - mse: 13.0640\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.3872 - mse: 12.3872\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4758 - mse: 8.4758\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.7252 - mse: 6.7252\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.2488 - mse: 6.2488\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.3806 - mse: 6.3806\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.0381 - mse: 8.0381\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0082 - mse: 11.0082\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3342 - mse: 8.3342\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2962 - mse: 10.2962\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1067 - mse: 10.1067\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.8848 - mse: 5.8848\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.6381 - mse: 6.6381\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8409 - mse: 10.8409\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.5721 - mse: 8.5721\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.8179 - mse: 7.8179\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.9691 - mse: 5.9691\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.8520 - mse: 6.8520\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2761 - mse: 7.2761\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.7321 - mse: 8.7321\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.2444 - mse: 8.2444\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.5263 - mse: 6.5263\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.7374 - mse: 6.7374\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7817 - mse: 8.7817\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.7977 - mse: 5.7977\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.5891 - mse: 5.5891\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.8432 - mse: 5.8432\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.2732 - mse: 5.2732\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.4513 - mse: 5.4513\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.0320 - mse: 14.0320\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.8842 - mse: 11.8842\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.2171 - mse: 5.2171\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.3874 - mse: 7.3874\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.6656 - mse: 7.6656\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2803 - mse: 7.2803\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.1787 - mse: 5.1787\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.2970 - mse: 6.2970\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0941 - mse: 10.0941\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4917 - mse: 8.4917\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6014 - mse: 7.6014\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.9214 - mse: 4.9214\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.4919 - mse: 5.4919\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.2652 - mse: 6.2652\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.3096 - mse: 10.3096\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.8486 - mse: 4.8486\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.6464 - mse: 5.6464\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.7581 - mse: 4.7581\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.8175 - mse: 4.8175\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.2764 - mse: 6.2764\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.9616 - mse: 11.9616\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.3173 - mse: 7.3173\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.0886 - mse: 5.0886\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.0419 - mse: 5.0419\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1067 - mse: 7.1067\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.4329 - mse: 12.4329\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.2037 - mse: 5.2037\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.5114 - mse: 4.5114\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.6321 - mse: 6.6321\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.2101 - mse: 6.2101\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.5063 - mse: 5.5063\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.2184 - mse: 8.2184\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5197 - mse: 8.5197\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.4345 - mse: 4.4345\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.3131 - mse: 4.3131\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.2680 - mse: 5.2680\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7531 - mse: 9.7531\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.2729 - mse: 9.2729\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.4737 - mse: 4.4737\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.2763 - mse: 4.2763\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.5330 - mse: 5.5330\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.2888 - mse: 5.2888\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.5610 - mse: 7.5610\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8425 - mse: 8.8425\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.8885 - mse: 5.8885\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.8081 - mse: 4.8081\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.0602 - mse: 4.0602\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1215 - mse: 4.1215\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.7131 - mse: 4.7131\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3066 - mse: 8.3066\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9646 - mse: 10.9646\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.0598 - mse: 5.0598\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.0182 - mse: 5.0182\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5820 - mse: 11.5820\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.3252 - mse: 10.3252\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.9647 - mse: 4.9647\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.9876 - mse: 4.9876\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 4.9637 - mse: 4.9637\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.8697 - mse: 3.8697\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.8703 - mse: 6.8703\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.8648 - mse: 8.8648\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.7864 - mse: 8.7864\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.4706 - mse: 6.4706\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.4092 - mse: 4.4092\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1815 - mse: 4.1815\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.9759 - mse: 3.9759\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.6529 - mse: 4.6529\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.7913 - mse: 6.7913\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.4509 - mse: 8.4509\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.7592 - mse: 3.7592\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.9434 - mse: 3.9434\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.5216 - mse: 4.5216\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.0834 - mse: 9.0834\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1634 - mse: 10.1634\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.1164 - mse: 5.1164\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.6340 - mse: 3.6340\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.2854 - mse: 4.2854\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.7451 - mse: 3.7451\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.5175 - mse: 3.5175\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.3929 - mse: 4.3929\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4638 - mse: 10.4638\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.4997 - mse: 7.4997\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1777 - mse: 4.1777\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.6080 - mse: 5.6080\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0588 - mse: 7.0588\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.8478 - mse: 4.8478\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.2472 - mse: 4.2472\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.2385 - mse: 5.2385\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.8239 - mse: 6.8239\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.5225 - mse: 5.5225\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.4289 - mse: 3.4289\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5337 - mse: 1.533 - 0s 6ms/step - loss: 3.4006 - mse: 3.4006\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.6658 - mse: 5.6658\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.9738 - mse: 12.9738\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6878 - mse: 9.6878\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.8877 - mse: 3.8877\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.4019 - mse: 3.4019\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2816 - mse: 3.2816\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2992 - mse: 3.2992\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3064 - mse: 3.3064\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.2506 - mse: 3.2506\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.0441 - mse: 4.0441\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.2053 - mse: 7.2053\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.5404 - mse: 12.5404\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.2751 - mse: 4.2751\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2618 - mse: 3.2618\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.7062 - mse: 3.7062\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.8012 - mse: 3.8012\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 3.9455 - mse: 3.9455\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.7982 - mse: 5.7982\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.1041 - mse: 8.1041\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.0592 - mse: 7.0592\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.6524 - mse: 5.6524\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.0401 - mse: 4.0401\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2527 - mse: 3.2527\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.2416 - mse: 3.2416\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0759 - mse: 3.0759\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.2302 - mse: 5.2302\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.4525 - mse: 10.4525\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3194 - mse: 3.3194\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3081 - mse: 3.3081\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0901 - mse: 3.0901\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0125 - mse: 3.0125\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.9698 - mse: 2.9698\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3408 - mse: 8.3408\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.3598 - mse: 13.3598\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.7936 - mse: 3.7936\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.2179 - mse: 3.2179\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.0062 - mse: 4.0062\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1607 - mse: 4.1607\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.0445 - mse: 3.0445\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.8203 - mse: 4.8203\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.9878 - mse: 4.9878\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.0893 - mse: 4.0893\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1846 - mse: 4.1846\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.4681 - mse: 6.4681\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6239 - mse: 9.6239\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.5056 - mse: 3.5056\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.9241 - mse: 2.9241\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8889 - mse: 2.8889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15e063b20>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.67401975,  0.01203257,  0.39865106],\n",
       "        [ 0.22308682, -0.46983638,  0.5329334 ],\n",
       "        [ 0.37956527,  0.53532845, -0.23622927],\n",
       "        [-0.41672984,  0.97656095, -0.43376473],\n",
       "        [-0.20253417,  0.5411604 ,  0.685938  ],\n",
       "        [-0.20973827, -0.22960497, -0.63407093]], dtype=float32),\n",
       " array([ 0.11374736,  0.11315627, -0.1142685 ], dtype=float32),\n",
       " array([[ 0.49160755],\n",
       "        [ 0.65653884],\n",
       "        [-0.3687637 ]], dtype=float32),\n",
       " array([0.11356481], dtype=float32)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x15c8f5f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 18:54:20.215466: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>18.988573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>20.494436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>20.179680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>24.055197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>12.080913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8   18.988573\n",
       "AK       18.1   20.494436\n",
       "AZ       18.6   20.179680\n",
       "AR       22.4   24.055197\n",
       "CA       12.0   12.080913"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9089440360749013"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with the Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=558\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=558\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `sigmoid` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:04:03.606252: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15fb090a0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:04:10.589808: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "      <th>pred_sigmoid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros  pred_sigmoid\n",
       "abbrev                                 \n",
       "AL       18.8         1.0           1.0\n",
       "AK       18.1         1.0           1.0\n",
       "AZ       18.6         1.0           1.0\n",
       "AR       22.4         1.0           1.0\n",
       "CA       12.0         1.0           1.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres['pred_sigmoid'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235.4076470588235"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fit()` the `model` and compare again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 243.7578 - mse: 243.7578"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 15:58:11.147593: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4076\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4077\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4076\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4076\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4076\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 235.4077 - mse: 235.4077\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 235.4076 - mse: 235.4076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ae12f730>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.10580671,  0.7500808 ,  0.16253507],\n",
       "        [-0.34526154, -0.5762522 , -0.7753689 ],\n",
       "        [-0.29335958, -0.2159903 , -0.16609263],\n",
       "        [ 0.26099467,  0.28944385, -0.42102963],\n",
       "        [-0.25016683,  0.3994559 , -0.5259208 ],\n",
       "        [ 0.22661805,  0.02153301,  0.28560925]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[-1.1483067 ],\n",
       "        [-0.9938561 ],\n",
       "        [-0.47182316]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 15:58:17.169034: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8         1.0\n",
       "AK       18.1         1.0\n",
       "AZ       18.6         1.0\n",
       "AR       22.4         1.0\n",
       "CA       12.0         1.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235.4076470588235"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `linear` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:06:38.016567: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16a0211f0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:06:43.422516: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "      <th>pred_sigmoid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.594013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.238089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.742601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.711784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.716588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros  pred_sigmoid\n",
       "abbrev                                 \n",
       "AL       18.8         1.0     17.594013\n",
       "AK       18.1         1.0     17.238089\n",
       "AZ       18.6         1.0     17.742601\n",
       "AR       22.4         1.0     22.711784\n",
       "CA       12.0         1.0     11.716588"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres['pred_sigmoid'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235.4076470588235"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.34451395, -0.16314414, -0.20206104],\n",
       "        [-0.6177763 ,  0.5099444 , -0.4447385 ],\n",
       "        [-0.69090617,  0.5364897 ,  0.19511676],\n",
       "        [-0.3502738 ,  0.6438615 ,  0.8683041 ],\n",
       "        [ 0.32621065,  0.10962319, -0.14200883],\n",
       "        [-0.42247236,  0.10126512, -0.56384903]], dtype=float32),\n",
       " array([-0.18409787,  0.18990237,  0.1837502 ], dtype=float32),\n",
       " array([[-0.11881167],\n",
       "        [ 0.57659256],\n",
       "        [ 0.18077397]], dtype=float32),\n",
       " array([0.18946521], dtype=float32)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:07:23.995965: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>17.594013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>17.238089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>17.742601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>22.711784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>11.716588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8   17.594013\n",
       "AK       18.1   17.238089\n",
       "AZ       18.6   17.742601\n",
       "AR       22.4   22.711784\n",
       "CA       12.0   11.716588"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9834952454696326"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `tanh` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:08:46.666148: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16b8c52e0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:08:50.996101: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "      <th>pred_sigmoid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>17.594013</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>17.238089</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>17.742601</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>22.711784</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>11.716588</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros  pred_sigmoid\n",
       "abbrev                                 \n",
       "AL       18.8   17.594013           1.0\n",
       "AK       18.1   17.238089           1.0\n",
       "AZ       18.6   17.742601           1.0\n",
       "AR       22.4   22.711784           1.0\n",
       "CA       12.0   11.716588           1.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres['pred_sigmoid'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9834952454696326"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.5778661 ,  0.25024602,  1.017356  ],\n",
       "        [ 1.5251609 , -0.07253256,  0.45896563],\n",
       "        [ 0.9107427 , -0.14757796,  0.8263705 ],\n",
       "        [ 1.1551406 ,  0.5162253 ,  1.0961491 ],\n",
       "        [ 1.3419919 ,  0.8816063 ,  1.4884272 ],\n",
       "        [ 1.5800475 ,  1.1244183 ,  1.560878  ]], dtype=float32),\n",
       " array([0.9818366 , 0.4632104 , 0.99483544], dtype=float32),\n",
       " array([[1.3824977],\n",
       "        [0.7467232],\n",
       "        [2.0802624]], dtype=float32),\n",
       " array([0.9798329], dtype=float32)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8         1.0\n",
       "AK       18.1         1.0\n",
       "AZ       18.6         1.0\n",
       "AR       22.4         1.0\n",
       "CA       12.0         1.0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235.4076488219523"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `relu` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.80496716,  0.7598734 , -0.42897052],\n",
       "        [ 0.10918653,  0.00948036, -0.10976821],\n",
       "        [ 0.21171498,  0.0022319 , -0.33985347],\n",
       "        [-0.3171079 ,  0.52273583,  0.29848576],\n",
       "        [-0.5062138 , -0.0099631 ,  0.14785284],\n",
       "        [-0.7037198 ,  0.5692266 , -0.36761624]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[ 0.14850485],\n",
       "        [-0.22410452],\n",
       "        [-1.160273  ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:13:39.599849: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1771c1520>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:13:46.291190: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "      <th>pred_sigmoid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros  pred_sigmoid\n",
       "abbrev                                 \n",
       "AL       18.8         0.0           0.0\n",
       "AK       18.1         0.0           0.0\n",
       "AZ       18.6         0.0           0.0\n",
       "AR       22.4         0.0           0.0\n",
       "CA       12.0         0.0           0.0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres['pred_sigmoid'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265.9880392156863"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.80496716,  0.7598734 , -0.42897052],\n",
       "        [ 0.10918653,  0.00948036, -0.10976821],\n",
       "        [ 0.21171498,  0.0022319 , -0.33985347],\n",
       "        [-0.3171079 ,  0.52273583,  0.29848576],\n",
       "        [-0.5062138 , -0.0099631 ,  0.14785284],\n",
       "        [-0.7037198 ,  0.5692266 , -0.36761624]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[ 0.14850485],\n",
       "        [-0.22410452],\n",
       "        [-1.160273  ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8         0.0\n",
       "AK       18.1         0.0\n",
       "AZ       18.6         0.0\n",
       "AR       22.4         0.0\n",
       "CA       12.0         0.0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265.9880392156863"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How are the predictions changing? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizers comparison in GIF ‚Üí https://mlfromscratch.com/optimizers-explained/#adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tesla's Neural Network Models is composed of 48 models trainned in 70.000 hours of GPU ‚Üí https://tesla.com/ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Year with a 8 GPU Computer ‚Üí https://twitter.com/thirdrowtesla/status/1252723358342377472"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Gradient Descent `SGD`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile & Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.3939669 ,  0.49886513,  0.5103427 ],\n",
       "        [ 0.03351152,  0.36945796,  0.47778463],\n",
       "        [ 0.7332885 ,  0.5005772 ,  0.49273205],\n",
       "        [-0.0714227 , -0.67955977, -0.37271243],\n",
       "        [ 0.05672973,  0.5415263 , -0.16182244],\n",
       "        [ 0.5573889 , -0.20461315, -0.33603796]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[-0.11912215],\n",
       "        [ 1.1910547 ],\n",
       "        [ 1.0008725 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:25:51.663632: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-11-17 19:25:51.764682: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=500, verbose=0, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan],\n",
       "        [nan, nan, nan]], dtype=float32),\n",
       " array([nan, nan, nan], dtype=float32),\n",
       " array([[nan],\n",
       "        [nan],\n",
       "        [nan]], dtype=float32),\n",
       " array([nan], dtype=float32)]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:26:09.457302: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8         NaN\n",
       "AK       18.1         NaN\n",
       "AZ       18.6         NaN\n",
       "AR       22.4         NaN\n",
       "CA       12.0         NaN"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### View History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `ADAM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FL</th>\n",
       "      <td>17.9</td>\n",
       "      <td>3.759</td>\n",
       "      <td>5.191</td>\n",
       "      <td>16.468</td>\n",
       "      <td>16.826</td>\n",
       "      <td>1160.13</td>\n",
       "      <td>144.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA</th>\n",
       "      <td>8.2</td>\n",
       "      <td>1.886</td>\n",
       "      <td>2.870</td>\n",
       "      <td>7.134</td>\n",
       "      <td>6.560</td>\n",
       "      <td>1011.14</td>\n",
       "      <td>135.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT</th>\n",
       "      <td>13.6</td>\n",
       "      <td>4.080</td>\n",
       "      <td>4.080</td>\n",
       "      <td>13.056</td>\n",
       "      <td>12.920</td>\n",
       "      <td>716.20</td>\n",
       "      <td>109.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX</th>\n",
       "      <td>19.4</td>\n",
       "      <td>7.760</td>\n",
       "      <td>7.372</td>\n",
       "      <td>17.654</td>\n",
       "      <td>16.878</td>\n",
       "      <td>1004.75</td>\n",
       "      <td>156.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NC</th>\n",
       "      <td>16.8</td>\n",
       "      <td>6.552</td>\n",
       "      <td>5.208</td>\n",
       "      <td>15.792</td>\n",
       "      <td>13.608</td>\n",
       "      <td>708.24</td>\n",
       "      <td>127.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                       \n",
       "FL       17.9     3.759    5.191          16.468       16.826      1160.13   \n",
       "MA        8.2     1.886    2.870           7.134        6.560      1011.14   \n",
       "VT       13.6     4.080    4.080          13.056       12.920       716.20   \n",
       "TX       19.4     7.760    7.372          17.654       16.878      1004.75   \n",
       "NC       16.8     6.552    5.208          15.792       13.608       708.24   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "FL          144.18  \n",
       "MA          135.63  \n",
       "VT          109.61  \n",
       "TX          156.83  \n",
       "NC          127.82  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset(name='car_crashes', index_col='abbrev')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Concepts in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_intercept': True,\n",
       " 'normalize': 'deprecated',\n",
       " 'copy_X': True,\n",
       " 'n_jobs': None,\n",
       " 'positive': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_intercept': True,\n",
       " 'normalize': 'deprecated',\n",
       " 'copy_X': True,\n",
       " 'n_jobs': None,\n",
       " 'positive': False,\n",
       " 'feature_names_in_': array(['speeding', 'alcohol', 'not_distracted', 'no_previous',\n",
       "        'ins_premium', 'ins_losses'], dtype=object),\n",
       " 'n_features_in_': 6,\n",
       " 'coef_': array([-0.02650334,  0.49252176,  0.17453205,  0.71257329, -0.00125105,\n",
       "         0.00643096]),\n",
       " '_residues': 35.75599620119316,\n",
       " 'rank_': 6,\n",
       " 'singular_': array([1265.56295658,  136.88075844,   40.51113699,   14.55337989,\n",
       "          10.99084201,    6.16130337]),\n",
       " 'intercept_': 1.4120634209126202}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_48148/3324602025.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fit' is not defined"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'algo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_48148/22777151.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'algo' is not defined"
     ]
    }
   ],
   "source": [
    "algo.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`algo = ?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_48148/861900531.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "algo = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.5440465 , -0.5944887 ,  0.1894604 ],\n",
       "        [-0.39043406,  0.19923973,  0.01172954],\n",
       "        [-0.12323105,  0.02964735, -0.58172023],\n",
       "        [ 0.65388715,  0.4604026 , -0.01621622],\n",
       "        [ 0.32393718, -0.31059176,  0.5557525 ],\n",
       "        [ 0.29998815,  0.30244648,  0.5110692 ]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[0.18368232],\n",
       "        [0.8821639 ],\n",
       "        [1.0883535 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adadelta', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')\n",
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:30:47.771781: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-11-17 19:30:48.001326: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=500, verbose=0, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.5420204 , -0.5965248 ,  0.1874278 ],\n",
       "        [-0.39250568,  0.19715802,  0.00965102],\n",
       "        [-0.12528914,  0.02757989, -0.5837849 ],\n",
       "        [ 0.65183276,  0.45833814, -0.01827728],\n",
       "        [ 0.32192993, -0.31260893,  0.55373853],\n",
       "        [ 0.29795647,  0.30040556,  0.5090314 ]], dtype=float32),\n",
       " array([-0.00209766, -0.00210741, -0.00210438], dtype=float32),\n",
       " array([[0.1816623 ],\n",
       "        [0.88417244],\n",
       "        [1.0863386 ]], dtype=float32),\n",
       " array([-0.00210574], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:30:58.155570: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>422.732758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>518.131470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>439.598328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>438.806305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>479.433990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8  422.732758\n",
       "AK       18.1  518.131470\n",
       "AZ       18.6  439.598328\n",
       "AR       22.4  438.806305\n",
       "CA       12.0  479.433990"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200408.45796179184"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### View History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `RMSPROP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does it take different times to get the best accuracy? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Another Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get to Know the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize some Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize One Sample/Row/Image/Explanatory Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS4AAAD8CAYAAADJwUnTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAc0ElEQVR4nO3df5RcdZnn8ffTv/Kz84uEEJJoAgYljkNgYhLBVZRxCJw5RsbBBV1Fl7OBGZld5/gHHNZd2LNn97A66DAjyraQBc5BGEdwjExWlDgI6IAJIZJfC4QQSUjIDwL53enu6mf/qEKqq/s+93ZXdVfd8HmdUydd9dzvrW9Xdz+593uf+/2auyMikidN9e6AiMhgKXGJSO4ocYlI7ihxiUjuKHGJSO4ocYlI7ihxiciwMbMVZrbXzDYmxM3M/s7MtprZc2Z2Xpb9KnGJyHC6G1gaxC8B5pUey4HvZtmpEpeIDBt3fxw4EGyyDLjXi54CJpnZjLT9ttSqg1m02SgfzbiRfEuRd5ROjtLlJ6yafVz8sXH++oFCpm2fee7EJqCz7KUOd+8YxNvNBHaUPd9Zem131KiqxGVmS4HbgGbgTne/Jdp+NONYbBdV85YiEnjaV1e9j/0HCjz9yKxM27bOeKnT3RdW8XYDJdnU+xCHnLjMrBm4HfgExSy5xsxWuvvmoe5TRBqBU/DekXqzncDssuezgF1pjaoZ41oEbHX3be7eBTxA8XxVRHLMgV4806MGVgJfKF1dXAIcdPfwNBGqO1Uc6Nx0ceVGZrac4tUCRjO2ircTkZHSS22OuMzsfuBCYKqZ7QRuAloB3P0OYBVwKbAVOAZ8Kct+q0lcmc5NSwN1HQATbIrm0BFpcI7TXaNTRXe/MiXuwJcHu99qEteQzk1FpLE5UKjNaeCwqWaMaw0wz8zmmlkbcAXF81URybkRHOMakiEfcbl7j5ldBzxCsRxihbtvqlnPRKQuHCg0+MzIVdVxufsqioNrInISGbFiiCEa0cp5EWl8jjf8GJcSl4j04Q7djZ23lLhEpJJRGLDaqXEocYlIHw706ohLRPJGR1wikivFAlQlLhHJEQe6vbHnGFXiEpE+HKPQ4JMjK3GJSD+9rlNFEckRjXGJSA4ZBY1xiUieFGdAVeISkRxxN7q8ud7dCClxnewsZayiyulLmk+ZEsbfuPisxNiE7z9V1XunfW/W0poY8+6u6t67Wmk/l8gITDnTqzEuEcmT4uC8ThVFJFc0OC8iOaPBeRHJpYIKUEUkTxyj2xs7NTR270RkxGlwXkRyxzGdKkp9WXNcSOg9PWG8acH8ML7lmvFx++PJsdaji8K2LcfjtWZaf7Y2jFdVq5VWI5byuWLxEUs1fbOW4M82/nFmpsF5EckVd1QOISL5Uhyc1y0/IpIzGpwXkVxxTBMJikj+6IhLRHKluK6iEpeI5IpWspY6C2t+SK/j2nHxpDD+uQ89EcZ/te+MxNjvRp0WtvUxYZiWP/5QGD/rO68mxnq2vxLvPGXOq7TPLU3z5MnJwUIhbFs4dCg5WIOpuorLk53EVxXNbDtwGCgAPe6+sBadEpH6cbeGP1WsRe8+5u4LlLRETh4Fb8r0yMLMlprZ82a21cxuGCA+0cx+Yma/NbNNZvaltH02dloVkRFXnI/LMj3SmFkzcDtwCTAfuNLMKu8j+zKw2d3PAS4EbjWztmi/1SYuB35mZs+Y2fKEji83s7VmtrabE1W+nYgMP6vlEdciYKu7b3P3LuABYFnFNg60m5kB44EDpNx1We3g/AXuvsvMTgV+bmb/z90f79Mj9w6gA2CCTRn+Wf5FpCrFcojMVxWnmln53e4dpb/5t8wEdpQ93wksrtjHt4GVwC6gHfi37h7eYV9V4nL3XaV/95rZjyhm18fjViLSyAZ5r+L+lPHtgTJg5QHMxcB64OPAmRQPgp5w98TLp0M+VTSzcWbW/tbXwJ8AG4e6PxFpHL00ZXpksBOYXfZ8FsUjq3JfAh7yoq3Ay8D7op1Wc8Q1HfhR8bSUFuD77v7TKvYnw6C3s7Oq9l3nHgnjfz4xnhNrdFN3YuyXTfF8W6/+YnYYL/xh3LfffbM9Mdb77Plh21M2xrVUE57dHcb3f2RmGN/3R8mjJtNTlpuc/OhLiTE7UH1pZnFam5oVoK4B5pnZXOBV4ArgsxXbvAJcBDxhZtOB9wLbop0O+bt0923AOUNtLyKNq1Y3Wbt7j5ldBzwCNAMr3H2TmV1bit8B/HfgbjPbQPHU8np33x/tV5XzItJHcXaI2lVKufsqYFXFa3eUfb2L4lBTZkpcItJH8Zafxi7xVOISkQqNf8uPEpeI9JOlKr6elLhEpI8aX1UcFkpcJ4NoKa2U6VmOfGZJGP/C/MfC+Evd08L4rLYDibHLT38mbMu/i+Pffv6jYfzotomJsaZx8efy2pL4VOnVZfH37d3xtDeT1yX/6TVdtSdse6greaqgwupRYdusdKooIrmiOedFJHcc6NERl4jkjU4VRSRfXKeKIpIzb00k2MiUuESkHx1xiUiuDHIiwbpQ4moEUR3WMFty/W/C+MfGb65q/zOD9bKOejitOG8WxoXxm+b/cxjfd1bytDbdHv/q3/liPO3NkaBGDKC5J/6ZLvn3zybGPj1lTdj26w9+IDHW5EfDtlk4Rk+vBudFJGc0xiUi+eI6VRSRnNEYl4jkkhKXiOSKYxQ0OC8ieaPBeRHJFdfgvGSSMmfWcHrxyKlh/PUJ48P4az2TwvgpzclLiLU3HQ/bzmkNF3phXyG5TguguTV5+bOulAVP/9v7fxLGO89uDeOtFi9vdv7oyqUF33b55i+EbcfFK3fVhCtxiUi+6CZrEckhHXGJSK64Q6FXiUtEckZXFUUkVxydKopI7mhwXkRyqI4VOpkocb3DTRuVXGcFMNq6w3ibxesH7uqenBh78fh7w7YvHIprzJZO3xTGu4NareZgnjBIr8M6vfWNMN7pcZ1X9KleMD2u01ofRmuj0U8VU29IMrMVZrbXzDaWvTbFzH5uZi+W/k3+7RSRXCleVWzK9KiXLO98N7C04rUbgNXuPg9YXXouIicJ92yPeklNXO7+OFC5jvoy4J7S1/cAn6ptt0Skntwt06NehjrGNd3ddwO4+24zSxyMMLPlwHKA0Ywd4tuJyEhx6puUshj2k1R373D3he6+sJVRw/12IlIDnvFRL0NNXHvMbAZA6d+9teuSiNSVg/dapkcWZrbUzJ43s61mNuB4uJldaGbrzWyTmf0ybZ9DTVwrgatKX18F/HiI+xGRBlSrMS4zawZuBy4B5gNXmtn8im0mAd8BPunu7wcuT9tv6hiXmd0PXAhMNbOdwE3ALcAPzOxq4JUsbySBlHUVrTmeO8p7kmupmifHlSofnbQhjO8rTAjjbxbicctJzccSY4d7RodtDxyP9/2+UbvD+LpjcxJj09riOqyo3wDbu6aG8XmjXgvjX99zUWJs9ujKa2F99Vz0kcSYP/2vYdusanjFcBGw1d23AZjZAxQv7pUv2PlZ4CF3f6X43p56BpeauNz9yoRQ8icvIrk1yHsVp5rZ2rLnHe7eUfZ8JrCj7PlOYHHFPs4CWs3sMaAduM3d743eVJXzItKXA9kT1353XxjEB9pR5fFcC/BHFA+GxgD/amZPufsLSTtV4hKRfmp4qrgTmF32fBZQOW/1TooJ8Chw1MweB84BEhNXY69BJCJ1kO2KYsarimuAeWY218zagCsoXtwr92Pg35hZi5mNpXgquSXaqY64RKS/Gh1xuXuPmV0HPAI0AyvcfZOZXVuK3+HuW8zsp8BzQC9wp7tvTN6rEpeIVPLazg7h7quAVRWv3VHx/BvAN7LuU4mrEaQMKFhL/GOKyiF2XH122PbjY+NluH7dOTOMT2s5HMajqWVmjDoYtm2f3hnG00oxprQkT9lzuDAmbDu26UQYT/u+z2uLl1b760fPS4y1/8HrYdsJrcEIT63yjebjEpH8aex7FZW4RKS/5LV0G4ISl4j0Nbg6rrpQ4hKRfjTnvIjkjxKXiOSOThVFJG9MR1ySxlrbwnhvZ1zPFJm6oSuM7y/Ey2hNaoqnd2lLWcarK6jjOn/Ky2HbfSm1VuuOzw3j7c3HE2PTmuI6rNmtcS3Vhs7ZYXzV0feE8av/9NHE2P0dnwjbtv3014kx8/jnlYkbZJwksF6UuESkPx1xiUjuKHGJSO4ocYlIrqgAVUTySFcVRSR/lLhEJG90xFVLwTJe1hLXI1lzyizVTXG8tzOYn6k3rmVK491xrVU1bvvf3w7jO3omhfHXuuN42jJehWB6lKeOTwzbjm7qDuPTWg6F8UO9cR1Y5HBvvHRaNM8YpPf9+lNeTIw9dPCPw7YjQmNcIpIrjk4VRSSHlLhEJG9MEwmKSO7oiEtE8sRcVxVFJI90VVFEckdHXNlVs35gWi2Ux2U1dXV82aIwvuNTcZ3Y5879TWLstZ72sO2zx+aE8YnBnFYA41LWH+z05Pq6XV2Tw7ZptVDRuokApwZ1XgWP6/Ze7Y77liatvm1nT7Dm4yfjucIm3TukLg1Ko58qplRlgpmtMLO9Zrax7LWbzexVM1tfelw6vN0UkRHjxauKWR71kpq4gLuBpQO8/i13X1B6rBogLiJ55RkfdZKauNz9ceDACPRFRBpF3hNX4Doze650Kpk4IGBmy81srZmt7SYeDxGRxvBWSUTao16Gmri+C5wJLAB2A7cmbejuHe6+0N0XtjJqiG8nIvK2ISUud9/j7gV37wW+B8SXxUQkX07GU0Uzm1H29DJgY9K2IpIzObiqmFrHZWb3AxcCU81sJ3ATcKGZLaCYc7cD19SiM1GdVrVaZpwWxrvnTg/jB84emxg7dlpcZbzg0i1h/IvT/08Y31eYEMZbLflz29F9Stj23LHbw/gvDs4P4/tbxofxqA7s/HHJc1IBvNmb/JkDnN7yRhi/fuufJ8amj41rpe58d3yhvNvjv9rnu+NhkYO9yfN5/cf5/xK2/RHTwnhNNHgdV2ricvcrB3j5rmHoi4g0AKPxC1AbqnJeRBpEgyeuasohRORklLEUIutRmZktNbPnzWyrmd0QbPdBMyuYWfI5fokSl4j015vxkcLMmoHbgUuA+cCVZtZv4LS03f8CHsnSPSUuEemnhkdci4Ct7r7N3buAB4BlA2z3V8CDwN4sO1XiEpH+stdxTX3rzpjSY3nFnmYCO8qe7yy99ntmNpNiWdUdWbvXUIPzJy75YBg/9T9vS4wtmLAzbDt/zJNhvLM3Xt4smmJl8/GZiTGAY71tYfzFrrhU42BPXBbQHBTU7O2Kp7W59eV4KazVi+Lfpa/tGuj++7c1jUn+b/n1QlxK8enx8fJjEP/MrnnX44mxM9ri/9gfPjojjO9KmfZmeuvBMD6ndV9i7M/aXwjbDns5xOCKS/e7+8IgPlCtUOXe/xa43t0LFixBWK6hEpeINIYalkPsBGaXPZ8F7KrYZiHwQClpTQUuNbMed/+npJ0qcYlIf7VLXGuAeWY2F3gVuAL4bJ+3cp/71tdmdjfwcJS0QIlLRAZQq9t53L3HzK6jeLWwGVjh7pvM7NpSPPO4VjklLhHpq8Y3UJcmGl1V8dqACcvdv5hln0pcItKHMfCIeiNR4hKR/hr8lh8lLhHpRzdZl7N4CbLF/3NN2Pyi9k2JsWMeTyOSVqeVVpcTmdgSL0V1ojv+mPd2x9PWpDlr1GuJscsmrA/bPv7txWH8w51/FcZf+ng8Jc/q48nTt+zrib/vK17+eBhf98rsML5kzsuJsQ+0vxq2Tauda2/uDOPRVEMAR3uTf1+f6ozr20aEEpeI5IrXd5LALJS4RKQ/HXGJSN5ojEtE8keJS0TyRkdcIpIvTqZJAutJiUtE+tBiGRW6Tx3Hrs8nrx1788S/D9t//8CSxNjs0QfCtu9u2x/GzxnzuzAeaW+Ka3reOyGu6Xn46Kww/tib7wvjM1rfTIw9cezMsO0DN38jjH/xr78axj+06towfmhO8lyVPePiv44J57wexr927j+H8TYrJMbeLMR1WlNGHQ3jk5rj2r00Ud1he1Pykm4Aze99T2LMtsfzzmWmxCUieWPe2JlLiUtE+qrx7BDDQYlLRPrRGJeI5I5u+RGR/NERl4jkyiBWqa4XJS4R6S/vicvMZgP3AqdRrKftcPfbzGwK8A/AHGA78Bl3fyPaV1M3jN2TfPL88KEFYV/OGJO8Ft3+7nj9wEeOfCCMzxoTdp2Jzcm1Ne8J5sMCWN85KYz/dN/7w/jpY+L1Bfd0T0yMvd49Lmx7LJgXCuCub30zjN+6J16X8bIp6xJj57TFdVpv9sbrFW9OWY/ycO/oxFinx/OzHUyp82oPfh8Auj3+02r25L+DSU1xjdihD5ySGCvsqf5YJA8FqFlWsu4BvuruZwNLgC+b2XzgBmC1u88DVpeei8hJwHo906NeUhOXu+9293Wlrw8DWyguob0MuKe02T3Ap4apjyIyknwQjzoZ1HGlmc0BzgWeBqa7+24oJjczO7X23RORejhpyiHMbDzwIPAVdz9UWi47S7vlwHKAtnFDn9ddREbQSTDGhZm1Ukxa97n7Q6WX95jZjFJ8BrB3oLbu3uHuC919YcuoeKBYRBqDebZHvaQmLiseWt0FbHH38ktMK4GrSl9fBfy49t0TkRHngHu2R51kOVW8APg8sMHM1pdeuxG4BfiBmV0NvAJcnraj5q5e2necSIz3enz6+Yv9ydO7TB99OGy7oH1HGH/+WHxpfcPx0xNj61reFbYd09wdxie2xdPijGtJ/swAprYmf+9zRw14IPx70dQvAGs64+/tL6Y9FsZf6UkeHvjJ0bPCtpuPJX/mAJNTloXbcCi5/bGetrDtiUL8p9HZE5fXTBwV/0w/OCV5GqXnmRG23XdOMFXQr8KmmeV+jMvdnyR5Re6LatsdEam3PNRxqXJeRPqq82lgFkpcItKPjrhEJH+UuEQkb3TEJSL54kChsTOXEpeI9KMjrnJHjtP0y2cTw//4swvC5v9l2T8mxn6ZsoTXw6/FdTeHuuLpXaaNTV6uakJQRwUwpTVe6mpiSj3SaIuXN3ujJ/mOhBNN8fQthcRKl6LXTiRPmQPwq955Yby7tzkxdiKIQXr924GuqWH89DEHE2OHe5KnvAHYfnhKGN9/cHwY7xwb/2k9WUheNm7paZvCtmP2Jv/MmuJflexqeFXRzJYCtwHNwJ3ufktF/HPA9aWnR4C/cPffRvvUEZeI9FOrIy4zawZuBz4B7ATWmNlKd99cttnLwEfd/Q0zuwToABZH+810r6KIvIPUdlqbRcBWd9/m7l3AAxSnxHr77dx/XTYJ6VNAvEIyOuISkQoGWPbB+almtrbseYe7d5Q9nwmU32+3k/ho6mrg/6a9qRKXiPQziJWs97v7wmhXA7w24M7N7GMUE9eH095UiUtE+qrt7KY7gdllz2cBuyo3MrM/BO4ELnH3eDECNMYlIv1knNIm21HZGmCemc01szbgCopTYv2emb0LeAj4vLu/kGWnOuISkX5qdVXR3XvM7DrgEYrlECvcfZOZXVuK3wH8V+AU4DulmZV7Uk4/MR/Bu8An2BRfbEOfCefg55Ykxs74y+fDtosmvRzG1x2K5516Jajr6U5ZRqu1KZ7caGxrVxgfnVLP1NacPKdWU8oxf29KHde45rhvaXOFTWhJnpeqvTmes6qpykmhmoPv/TcH51S17/aU77vH49+JD018KTG24uXzw7YTL92aGHvaV3PID2SbVz3BhPaZvujcv8y07eonvvZMWpIZDjriEpG+fFBXFetCiUtE+mvsvKXEJSL9DaIcoi6UuESkPyUuEckVB/K+WIaIvLMYrlNFEcmh3sY+5Br5xNUUzMHUG6/xN/G+pxJjr98Xv+0PP31xGF9845ow/qdzkqcHel/bnrBta8px9+iUeqVxTXFZTmfwv2ParRFPHp8dxgspe/jFG2eH8Te7xyTG9hybELZtDerTsojW6TzeE89TdvB4PF9Xc1N8RNL5WDxX2Mubk+ePm7gq/l0cdjpVFJE80qmiiOSPEpeI5IsWhBWRvNEqPyKSRxrjEpH8UeISkVxxoDfnicvMZgP3AqdRrO7ocPfbzOxm4D8A+0qb3ujuq1LfMaVWa7iMe/DpML7xwbj9RuYmxuyDnwzbHj8tuZYJYNTr8dxOh98dt5/wUvK6jU0n4oX2en+7JYynO1JF20NhNJ6FrDptKfFpVb9Dpok8G9TJMTjfA3zV3deZWTvwjJn9vBT7lrv/zfB1T0TqIu+Jy913A7tLXx82sy0UlxwSkZORA4XGLp0f1GIZZjYHOBd467zrOjN7zsxWmNnkhDbLzWytma3tJj4lEpFG4OC92R51kjlxmdl44EHgK+5+CPgucCawgOIR2a0DtXP3Dndf6O4LWxlVfY9FZPjVbpWfYZHpqqKZtVJMWve5+0MA7r6nLP494OFh6aGIjKwcXFVMPeKy4npBdwFb3P2bZa/PKNvsMmBj7bsnInVxEhxxXQB8HthgZutLr90IXGlmCyjm5+3ANcPQv1zwNRvCeDxBSroJvx5628YeYpWGdRJcVXwSBlx8L71mS0Tyxx0K9am3zEqV8yLSX96PuETkHUiJS0TyxRv+qqISl4j05eB1LC7NQolLRPpr8Ft+lLhEpC93LU8mIjmkwXkRyRvXEZeI5MvJMZGgiLyT5OAmayUuEenDAW/wW34GNZGgiLwDeG0nEjSzpWb2vJltNbMbBoibmf1dKf6cmZ2Xtk8dcYlIP16jU0UzawZuBz4B7ATWmNlKd99cttklwLzSYzHFSUoXR/vVEZeI9Fe7I65FwFZ33+buXcADwLKKbZYB93rRU8Ckivn++hnRI67DvLH/Uf/h78pemgrsH8k+DEKj9q1R+wXq21DVsm/vrnYHh3njkUf9h1Mzbj7azNaWPe9w946y5zOBHWXPd9L/aGqgbWZSWqRnICOauNy9z3J1ZrbW3ReOZB+yatS+NWq/QH0bqkbrm7svreHuBprLr/I8NMs2fehUUUSG005gdtnzWcCuIWzThxKXiAynNcA8M5trZm3AFcDKim1WAl8oXV1cAhwsreeaqN5XFTvSN6mbRu1bo/YL1LehauS+VcXde8zsOuARoBlY4e6bzOzaUvwOitPAXwpsBY4BX0rbr3mDl/aLiFTSqaKI5I4Sl4jkTl0SV9otAPVkZtvNbIOZra+oT6lHX1aY2V4z21j22hQz+7mZvVj6d3ID9e1mM3u19NmtN7NL69S32Wb2L2a2xcw2mdl/Kr1e188u6FdDfG55MuJjXKVbAF6g7BYA4MqKWwDqxsy2Awvdve7Fimb2EeAIxariPyi99nXggLvfUkr6k939+gbp283AEXf/m5HuT0XfZgAz3H2dmbUDzwCfAr5IHT+7oF+foQE+tzypxxFXllsABHD3x4EDFS8vA+4pfX0PxV/8EZfQt4bg7rvdfV3p68PAFoqV2HX97IJ+ySDVI3Ellfc3Cgd+ZmbPmNnyendmANPfqnEp/XtqnftT6brSHf4r6nUaW87M5gDnAk/TQJ9dRb+gwT63RlePxDXo8v4RdoG7n0fxjvUvl06JJJvvAmcCCyjeZ3ZrPTtjZuOBB4GvuPuheval3AD9aqjPLQ/qkbgGXd4/ktx9V+nfvcCPKJ7aNpI9b905X/p3b53783vuvsfdC15clO971PGzM7NWisnhPnd/qPRy3T+7gfrVSJ9bXtQjcWW5BaAuzGxcadAUMxsH/AmwMW414lYCV5W+vgr4cR370kfFVCSXUafPzswMuAvY4u7fLAvV9bNL6lejfG55UpfK+dLl3r/l7VsA/seId2IAZnYGxaMsKN4O9f169s3M7gcupDjtyR7gJuCfgB8A7wJeAS539xEfJE/o24UUT3cc2A5ck3bP2TD17cPAE8AG4K1Jo26kOJ5Ut88u6NeVNMDnlie65UdEckeV8yKSO0pcIpI7SlwikjtKXCKSO0pcIpI7SlwikjtKXCKSO/8fCUNW3D7yEOgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Variable Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_label = train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[idx_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prediction with `linear`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Flatten(input_shape=(28, 28)))\n",
    "model.add(layer=Dense(units=10, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 16:08:03.315935: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "probability_model = model.predict(train_images[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.46088925, -0.71803015,  1.8104963 , -0.32227725, -1.2279141 ,\n",
       "         0.87708545, -0.4228993 , -1.3560803 ,  0.837188  , -0.5062433 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_label_predicted = probability_model.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_label_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pullover'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[idx_label_predicted]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prediction with `sigmoid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Flatten(input_shape=(28, 28)))\n",
    "model.add(layer=Dense(units=10, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 16:08:11.067917: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "probability_model = model.predict(train_images[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51757556, 0.28019416, 0.22480458, 0.56114507, 0.6312654 ,\n",
       "        0.5552896 , 0.5547205 , 0.75376225, 0.5698508 , 0.23755492]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_label_predicted = probability_model.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_label_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sneaker'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[idx_label_predicted]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prediction with `relu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Flatten(input_shape=(28, 28)))\n",
    "model.add(layer=Dense(units=10, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 16:08:19.007563: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "probability_model = model.predict(train_images[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.6324478 , 0.1789244 , 0.13540947, 0.        ,\n",
       "        1.7053415 , 1.4692657 , 0.26082066, 0.44540834, 0.0634038 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_label_predicted = probability_model.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_label_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sandal'"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[idx_label_predicted]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the end, what should be a correct `activation` function for this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `loss` Function Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `activation` Function Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Number of `epochs` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `optimizer` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `kernel_initializer` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The number of Neurons & Hidden Layers\n",
    "\n",
    "> Why Deep Learning?\n",
    ">\n",
    "> - Non-lineality patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/beginners-ask-how-many-hidden-layers-neurons-to-use-in-artificial-neural-networks-51466afa0d3e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.87287&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Mathematical Formula\n",
    "- Weights / Kernel Initializer\n",
    "- Loss Function\n",
    "- Activation Function\n",
    "- Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What cannot you change arbitrarily of a Neural Network?\n",
    "\n",
    "- Input Neurons\n",
    "- Output Neurons\n",
    "- Loss Functions\n",
    "- Activation Functions"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Jes√∫s L√≥pez @sotastica"
   }
  ],
  "kernelspec": {
   "display_name": "DeepLearning Python",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
